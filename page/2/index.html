<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="Recap">
<meta property="og:url" content="https://zhangzhejian.com/page/2/index.html">
<meta property="og:site_name" content="Recap">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Recap">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zhangzhejian.com/page/2/"/>





  <title>Recap</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Recap</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">zhejian</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/02/04/NOTE-Week-4-Pattern-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/04/NOTE-Week-4-Pattern-Recognition/" itemprop="url">(PR) Neural Networks</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-04T13:04:41+00:00">
                2019-02-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Overview:</p>
<ul>
<li>What is a Neural Network</li>
<li>Why</li>
<li>Types of artificial Neural network</li>
</ul>
<h2 id="What-is-NN"><a href="#What-is-NN" class="headerlink" title="What is NN"></a>What is NN</h2><p>A Neural Network is a network of connected elements called neurons.</p>
<ul>
<li>Biological</li>
<li>Artificial</li>
</ul>
<p>a Neuron has:</p>
<ul>
<li>A cell body</li>
<li>An axon(轴突)</li>
<li>Many Synapses(突触)</li>
<li>Many Dendrites(树突)</li>
</ul>
<p>Synapses are the connections between the axon of one neuron and the dendrites of another neuron.</p>
<h3 id="Information-flow-through-a-neuron"><a href="#Information-flow-through-a-neuron" class="headerlink" title="Information flow through a neuron"></a>Information flow through a neuron</h3><h2 id="Artificial-NN"><a href="#Artificial-NN" class="headerlink" title="Artificial NN"></a>Artificial NN</h2><p>A network of simple processing units which communicate by sending signals to each other over weighted connections</p>
<p>An ANN is a parallel computational system consisting of many simple processing elements connected together in a specific way in order to perform a particular task.</p>
<p>Also known as:</p>
<ul>
<li>Parallel distributed processing(PDP)</li>
<li>connectionist models</li>
</ul>
<p><img src="https://i.postimg.cc/7L66dRwM/pr-4-1.png" alt=""></p>
<h3 id="Why-ANN"><a href="#Why-ANN" class="headerlink" title="Why ANN"></a>Why ANN</h3><p>From a biological perspective:</p>
<ul>
<li>To build models to understand brain function by simulation</li>
<li>To mimic(模仿) certain <u>cognitive capabilities(认知能力)</u> of human beings.</li>
</ul>
<p>From a pratical perspective</p>
<ul>
<li>powerful computational</li>
<li>Any continuous function from input to output can be implemented in a three-layer ANN</li>
</ul>
<h3 id="Processing-units"><a href="#Processing-units" class="headerlink" title="Processing units:"></a>Processing units:</h3><p><img src="https://i.postimg.cc/25K6Dx5p/pr-4-2.png" alt=""></p>
<h4 id="Layers"><a href="#Layers" class="headerlink" title="Layers"></a>Layers</h4><ul>
<li>Visible<ul>
<li>receive inputs from, or send outputs to, the external environment</li>
<li>Input: receive signals from the environment</li>
<li>Output: send signals to the environment</li>
</ul>
</li>
<li>Hidden<ul>
<li>Only receive inputs and send output to other processing units</li>
</ul>
</li>
</ul>
<h4 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h4><ul>
<li>Transfer function<ul>
<li>determines how the inputs are integrated</li>
</ul>
</li>
<li>Activation function <ul>
<li>determines the output the neuron produces</li>
</ul>
</li>
</ul>
<h4 id="Weights"><a href="#Weights" class="headerlink" title="Weights"></a>Weights</h4><p>Connection weights can be defined by:</p>
<ul>
<li>Setting weights explicitly using prior knowledge</li>
<li>Optimising connectivity to achieve some objective(e.g. using a genetic algorithm)</li>
<li>Training the network by training data and allowing it to adapt the connection weights<ul>
<li>Supervised<ul>
<li>e.g. Delta Learning Rule $\delta w_{ji} = \eta(t_j-y_j)x_i$</li>
</ul>
</li>
<li>Unsupervised <ul>
<li>e.g. Hebbian Learning rule $\delta w_{ji} = \eta y_jx_i$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="ANN-types"><a href="#ANN-types" class="headerlink" title="ANN types"></a>ANN types</h2><p>General Types:</p>
<ol>
<li>Linear Threshold Unit (or Perceptron) </li>
<li>Competitive Learning Networks </li>
<li>Inhibitory Feedback Networks </li>
<li>Autoencoder Networks </li>
<li>Multilayer Perceptrons </li>
<li>Radial Basis Function Networks </li>
<li>Convolutional Neural Networks </li>
<li>Restricted Boltzmann Machines </li>
<li>Hopfield Networks </li>
<li>Kohonen Networks </li>
<li>Capsule Networks</li>
</ol>
<h2 id="LInear-Threshold-Unit-perceptron感知器"><a href="#LInear-Threshold-Unit-perceptron感知器" class="headerlink" title="LInear Threshold Unit (perceptron感知器)"></a>LInear Threshold Unit (perceptron感知器)</h2><p><img src="https://i.postimg.cc/25K6Dx5p/pr-4-2.png" alt=""></p>
<script type="math/tex; mode=display">
y_j = H(\sum_i w_{ji}x_i - \theta_j)\\
y = H(\mathcal{w}\mathcal{x} - \theta)\\
\text{if $x_0 = 1, w_0 = -\theta$  }\\
y = H(wx)</script><p>$\theta$ is the threshold</p>
<p>$\sum_i w_{ji}x_i$ is the transfer function </p>
<p>$H(x)$ is an impulse function</p>
<p><img src="https://i.postimg.cc/90h5y4fg/pr-4-3.png" width="200px"></p>
<p>The learning methods are the same as Linear discriminant function:</p>
<ul>
<li>MSE(Widrow-Hoff)</li>
<li>Perceptron Learning</li>
</ul>
<p>In Addition:</p>
<ul>
<li>Delta Learning Rule</li>
<li>Hebbian Learning Rule</li>
</ul>
<h2 id="Delta-Learning-Rule-supervised"><a href="#Delta-Learning-Rule-supervised" class="headerlink" title="Delta Learning Rule(supervised)"></a>Delta Learning Rule(supervised)</h2><p>Adjust weights in proportion to the difference between:</p>
<ul>
<li>the <strong>desired output t</strong></li>
<li>the <strong>actual output y</strong></li>
</ul>
<p>$w =[-\theta, w_1]$ and $x = [1,x]^T$</p>
<ul>
<li>Sequential(online) update:$w = w + \eta(t-y)x^t$ </li>
</ul>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> true</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> =<span class="number">1</span>:m</span><br><span class="line">        w = w + alpha*(t(:,<span class="built_in">i</span>)-heaviside(w*x(<span class="built_in">i</span>,:)'))*x(<span class="built_in">i</span>,:);</span><br><span class="line">    <span class="keyword">end</span> </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isequal</span>(heaviside(w*x'),t)</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Batch:$w = w + \eta \sum_p (t_p-y_p)x_p^t$ </li>
</ul>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> true</span><br><span class="line">    sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> =<span class="number">1</span>:m</span><br><span class="line">        sum = sum+ (t(:,<span class="built_in">i</span>)-heaviside(w*x(<span class="built_in">i</span>,:)'))*x(<span class="built_in">i</span>,:);</span><br><span class="line">    <span class="keyword">end</span> </span><br><span class="line">    w = w + alpha * sum;</span><br><span class="line">    display(w)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isequal</span>(heaviside(w*x'),t)</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>Two types of update:</p>
<ul>
<li>false negative(t=1,y=0)<ul>
<li>$w = w + \eta (t-y)x^t$</li>
</ul>
</li>
<li>false positive(t=0,y=1)<ul>
<li>$w = w + \eta \sum_p(t_p-y_p)x_p^t$</li>
</ul>
</li>
</ul>
<h4 id="Delta-Learning-rule-via-Gradient-descent"><a href="#Delta-Learning-rule-via-Gradient-descent" class="headerlink" title="Delta Learning rule via Gradient descent"></a>Delta Learning rule via Gradient descent</h4><p><img src="https://i.postimg.cc/tRM2MYQs/pr-4-4.png" alt=""></p>
<p>Note: Iterate till convergence. If dataset not linearly separable, <strong>learning will not converge</strong></p>
<h2 id="Hebbian-Learning-Rule-unsupervised"><a href="#Hebbian-Learning-Rule-unsupervised" class="headerlink" title="Hebbian Learning Rule(unsupervised)"></a>Hebbian Learning Rule(unsupervised)</h2><p>Sequential Update:</p>
<script type="math/tex; mode=display">
w = w+ \eta yx^t</script><p>Strengthen the connection between an active neuron and any active inputs.</p>
<h2 id="Competitive-Learning"><a href="#Competitive-Learning" class="headerlink" title="Competitive Learning"></a>Competitive Learning</h2><p>Output units compete for the. right to respond to the input. Competition means that activity of some neurons is suppressed by other neurons.</p>
<p>Implementation methods:</p>
<ul>
<li><p>Inhibitory lateral weights    </p>
<ul>
<li>Requires outputs to be determined iteratively</li>
</ul>
</li>
<li><p>selection process that chooses the “winning” neuron</p>
<ul>
<li>simpler and more stable</li>
<li>Winner-takes-all(WTA) can be used with Hebbian learning to perform <strong>clustering</strong>.</li>
</ul>
</li>
</ul>
<p><img src="https://i.postimg.cc/wjhPfnX7/PR-4-comp.png" zoom="70%"></p>
<h2 id="Negative-Feedback-Network"><a href="#Negative-Feedback-Network" class="headerlink" title="Negative Feedback Network"></a>Negative Feedback Network</h2><p>Output neurons compete to receive inputs, rahter than compete to produce output.(require outputs to be determined iteratively)</p>
<ol>
<li>Activation<ol>
<li>Initial y to 0</li>
<li>Perform several iterations of:<ul>
<li>update input units:  $e = x - W^Ty$</li>
<li>update output units: $y = y + \alpha We$</li>
</ul>
</li>
</ol>
</li>
<li>Learning $W = W +\beta ye^T$</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">W = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>;<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line">x = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>]';</span><br><span class="line">m = <span class="number">2</span>;</span><br><span class="line">y = <span class="built_in">zeros</span>(m);</span><br><span class="line">y = y(:,<span class="number">1</span>)</span><br><span class="line">alpha = <span class="number">0.25</span>;</span><br><span class="line"><span class="built_in">i</span>=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> true</span><br><span class="line">    e = x - W'*y</span><br><span class="line">    y = y + alpha*W*e</span><br><span class="line">    <span class="built_in">i</span> = <span class="built_in">i</span>+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">i</span> ==<span class="number">6</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>Consider</p>
<ul>
<li>$W^Ty $ as being a <strong>reconstruction</strong> of the input</li>
<li>$e$ as being the error between the input and the reconstruction</li>
<li>Activation<ul>
<li>Tries to minimise reconstruction error $e$</li>
<li>Tries to find $y$ values that accurately reconstruct the input</li>
</ul>
</li>
<li>Learning<ul>
<li>Adjust weights to accurately reconstruct the input</li>
</ul>
</li>
</ul>
<h2 id="Autoencoder-Networks"><a href="#Autoencoder-Networks" class="headerlink" title="Autoencoder Networks"></a>Autoencoder Networks</h2><p>Represent the reconstruction using a separate neural population, $r$,and remove the inhibitory feedback connections</p>
<script type="math/tex; mode=display">
y = f(Wx)\\</script><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ol>
<li>Difference between Negative Feedback Network and process selection</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/02/04/NOTE-Week-4-Distributed-System/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/04/NOTE-Week-4-Distributed-System/" itemprop="url">(DS) Replica Management</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-04T12:04:42+00:00">
                2019-02-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Overview:</p>
<ol>
<li>Data distribution Strategies</li>
<li>Replication architecture</li>
<li>Consistency in Replication</li>
</ol>
<h2 id="Data-distribution-models"><a href="#Data-distribution-models" class="headerlink" title="Data distribution models"></a>Data distribution models</h2><p>Distributing a service means replicating hardware and/or distributing data</p>
<ul>
<li>Duplication(复制): Copies of the same data are maintained at several hosts<ul>
<li><strong>Replication</strong>: maintain copies in a proactive manner</li>
<li><strong>Caching</strong>: maintain in reactive manner</li>
</ul>
</li>
<li>Fragmentation(分割): The data is divided into parts and split between hosts<ul>
<li>Vertical Partitioning</li>
<li>Horizontal Partitioning</li>
</ul>
</li>
<li>Migration(迁移): Data moves from one host to another</li>
</ul>
<h2 id="Duplication"><a href="#Duplication" class="headerlink" title="Duplication"></a>Duplication</h2><h3 id="Variety-of-Data"><a href="#Variety-of-Data" class="headerlink" title="Variety of Data"></a>Variety of Data</h3><h4 id="Types-of-information-stored-by-applications"><a href="#Types-of-information-stored-by-applications" class="headerlink" title="Types of information stored by applications:"></a>Types of information stored by applications:</h4><ul>
<li>Content</li>
<li>user information</li>
<li>application: Executable code</li>
</ul>
<h4 id="Longevity-of-data"><a href="#Longevity-of-data" class="headerlink" title="Longevity of data:"></a>Longevity of data:</h4><ul>
<li>Persistent: Characterises and shapes the service over time.构建，塑造了整个服务。</li>
<li>Working: Used internally to produce required functionality; usually possible to recover from loss but needs low latency 互相交流的数据</li>
</ul>
<h3 id="Database-Fragmentation"><a href="#Database-Fragmentation" class="headerlink" title="Database Fragmentation"></a>Database Fragmentation</h3><ul>
<li>Vertical垂直:<ul>
<li>a table is divided with some columns</li>
</ul>
</li>
<li>Horizontal水平:<ul>
<li>a table is divided with some rows on one host and other rows on another</li>
<li>Sharding</li>
</ul>
</li>
</ul>
<p>NOTE:数据库的垂直于水平分割参考《构建高性能web站点》郭欣。</p>
<h3 id="Sharding-碎片"><a href="#Sharding-碎片" class="headerlink" title="Sharding(碎片):"></a>Sharding(碎片):</h3><p> horizontal partitioning across hosts, plus replication of related data in other <strong>small tables</strong> so that one host can resolve queries without further comms<br>通过碎片这种小规模的表来储存一些公用数据，方便做union或者查询操作。</p>
<h4 id="Suitability-of-Sharding"><a href="#Suitability-of-Sharding" class="headerlink" title="Suitability of Sharding"></a>Suitability of Sharding</h4><ul>
<li>Read-only transactions or <strong>temporary</strong> for a transaction</li>
</ul>
<h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><p>WHY:</p>
<ul>
<li>Fault tolerance</li>
<li>Spreading the load</li>
</ul>
<p><strong>Issues: whether the resource has state</strong></p>
<h4 id="Objectives"><a href="#Objectives" class="headerlink" title="Objectives"></a>Objectives</h4><ul>
<li>Trasparency:  ensure the request is the same regardless of  which replicas are functioning </li>
<li>Consistency: The result is the same regardless of which replica(s) are used</li>
</ul>
<h4 id="Location-Aware-Replication"><a href="#Location-Aware-Replication" class="headerlink" title="Location-Aware Replication"></a>Location-Aware Replication</h4><p>To make the most of distributed replicas, we will want each client to use a replica physically close to it, to reduce latency</p>
<h2 id="Replication-architecture"><a href="#Replication-architecture" class="headerlink" title="Replication architecture"></a>Replication architecture</h2><h3 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h3><ul>
<li>Clients: A,B,C</li>
<li>Sequence numbers: 1, 2, 3</li>
<li>Request with i from client c is :<strong>Rci</strong></li>
<li>The state of a resource replica: <strong>s</strong></li>
<li>State reached after processing request <strong>Rci</strong> from state <strong>s</strong>: Rci(s)</li>
</ul>
<h3 id="Rules-for-maintaining-consistency"><a href="#Rules-for-maintaining-consistency" class="headerlink" title="Rules for maintaining consistency"></a>Rules for maintaining consistency</h3><ul>
<li>Each manager has same initial state</li>
<li>For a client c, it processes Rci before Rci+1 <strong>(FIFO ordering)</strong></li>
<li>If RAi is a potential cause of RBj, for any A, B, i, j, then it processes RAi before RBj <strong>(casual ordering)</strong></li>
<li>Every manager processes requests in the same order <strong>(total ordering)</strong></li>
</ul>
<h3 id="States"><a href="#States" class="headerlink" title="States"></a>States</h3><ol>
<li>initial: not yet received Rci</li>
<li>pending: Received Rci, but do not know if it is stable</li>
<li>stable: Rci is known to be stable</li>
<li>Processed: Rci has been processed</li>
</ol>
<h3 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h3><ul>
<li>A read request does not alter the state of the resource, so RA1(s) = s</li>
<li>Some request commute: RA1(RA2(s)) = RA2(RA1(s))<ul>
<li>both read requests</li>
<li>updates made on distinct parts of the data</li>
</ul>
</li>
</ul>
<p>Requires:</p>
<ul>
<li><strong>Agreement</strong> between all managers about the requests they have been sent </li>
<li><strong>Ordering</strong>  the rquests according to the rulse</li>
</ul>
<h3 id="Approach"><a href="#Approach" class="headerlink" title="Approach"></a>Approach</h3><ul>
<li>Primary Backup Approach:<ul>
<li>Clients only communicate with one manager(primary) others are backups.类似于主从复制，但是没有读写分离，读写操作只访问主数据库</li>
</ul>
</li>
<li>State Machine Approach: treats all managers on an equal footing</li>
</ul>
<h2 id="State-Machine"><a href="#State-Machine" class="headerlink" title="State Machine"></a>State Machine</h2><p><img src="https://i.postimg.cc/d0gwbKMK/DS-4-1.png" width="500px"></p>
<p>Connectivity:</p>
<p><img src="https://i.postimg.cc/HLrTvkh2/DS-4-2.png" width="500px"></p>
<p>Each pair of managers has its own link which fails independently of other links</p>
<h3 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements:"></a>Requirements:</h3><p>Agreement:</p>
<ol>
<li>Each front end must be able to broadcast requests to all managers</li>
<li>Each front end must know that the managers have received a request, Reliable Broadcasts</li>
</ol>
<p>Ordering:</p>
<ol>
<li>A unique identifier to each request</li>
<li>Enable same ordering to be maintained at each manager</li>
</ol>
<ul>
<li>Replica-Generated identifiers</li>
<li>State machine with RM broadcasts</li>
<li>primary backup approach</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/01/29/NOTE-Week-3-Cryptocurrency/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/29/NOTE-Week-3-Cryptocurrency/" itemprop="url">(Blockchain) Network Layer and information Propagation</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-29T19:06:43+00:00">
                2019-01-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview:"></a>Overview:</h2><ul>
<li>Difference between P2P and C-S model</li>
<li><p>P2P Problems: how a new node joins the network</p>
<ul>
<li>Bootstrapign</li>
<li>File sharing<ul>
<li>how to identify other nodes sharing</li>
</ul>
</li>
</ul>
</li>
<li><p>Data Propagation </p>
<ul>
<li>Transactions and blocks</li>
<li>0-conf and double-spending</li>
</ul>
</li>
<li>Node misbehavior</li>
<li>Network based attacks</li>
<li>Network topology</li>
<li>Address Propagation</li>
</ul>
<h2 id="Difference-between-P2P-and-Client-Server-model"><a href="#Difference-between-P2P-and-Client-Server-model" class="headerlink" title="Difference between P2P and Client-Server model"></a>Difference between P2P and Client-Server model</h2><ul>
<li>Servers:<ul>
<li>Specific resources upon request</li>
<li>Provide different types of services</li>
</ul>
</li>
<li>Client:<ul>
<li>Resource/Service requesters</li>
<li>do not share resources or provide any service</li>
</ul>
</li>
</ul>
<ul>
<li>P2P<ul>
<li>All actors (peers) are equal and have both client and server capabilities</li>
<li>Services / resources can be shared between several peers or found in a single location</li>
<li>Each peer can choose what to serve/request</li>
<li>Quite usual paradigm for distributed ﬁle sharing (e.g: BitTorrent)</li>
</ul>
</li>
</ul>
<p>Problem: New nodes how to add into the network and resource searching</p>
<h2 id="P2P-Bootstrapping"><a href="#P2P-Bootstrapping" class="headerlink" title="P2P Bootstrapping"></a>P2P Bootstrapping</h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/01/29/NOTE-Week-3-OME/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/29/NOTE-Week-3-OME/" itemprop="url">Single-source shortest-paths problem (I)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-29T16:01:35+00:00">
                2019-01-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Overview:</p>
<ol>
<li>Basic concepts</li>
<li>Bellman-Fodr algorithm</li>
</ol>
<p>最短路径问题本质上是组合优化问题</p>
<h3 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h3><p>Definition of G = (V,E)</p>
<p>Weight Function $w: E \to R$ mapping edges (u,v) to real-valued weights w(u,v)</p>
<p>The weight of a path $p = <v_0,v_1,...,v_k>$ is the sum of weights of its constituent edges:</v_0,v_1,...,v_k></p>
<script type="math/tex; mode=display">
w(p) = \sum_{i=1}^k w(v_{i-1},v_i)</script><p>The shortest-path weight from u to v is:</p>
<script type="math/tex; mode=display">
\delta(u,v) = \begin{cases} min\{(w(p)|u \to v\} &\text{if there is a path from u $\to$ v}\\
\infty &\text{otherwise}
\end{cases}</script><p>A shortest  path from u to v is then defined as any path p with weight $w(p) = \delta(u,v)$</p>
<h3 id="Properties-of-Shortest-paths"><a href="#Properties-of-Shortest-paths" class="headerlink" title="Properties of Shortest paths"></a>Properties of Shortest paths</h3><ul>
<li>A subpath of a shortest path is a shortest path</li>
</ul>
<h3 id="Cicles-in-shortest-paths-problem"><a href="#Cicles-in-shortest-paths-problem" class="headerlink" title="Cicles in shortest-paths problem"></a>Cicles in shortest-paths problem</h3><ul>
<li>if there is a negative cycle on a path from s to v, then, by convention, $\delte(s,v) =- \infty$</li>
<li>Thus shortest path s cannot contain negative-weight cycles</li>
</ul>
<h3 id="Bellman-Ford-algorithm-can-deal-with-negative-cycle"><a href="#Bellman-Ford-algorithm-can-deal-with-negative-cycle" class="headerlink" title="Bellman-Ford algorithm(can deal with negative cycle)"></a>Bellman-Ford algorithm(can deal with negative cycle)</h3><p>The main idea of the Algorithm is to use the iteration relax action to calculate the shortest path from the source to every point till convergency. If there is a negative cycle, then after (V-1) times iterations, the grahpy will not be convergence.</p>
<h3 id="Initialise-Single-Source"><a href="#Initialise-Single-Source" class="headerlink" title="Initialise Single Source"></a>Initialise Single Source</h3><p>Definition:</p>
<p>G be a directed graphy and $s\in G.V $ the source node. For each $v\in V$, we define:</p>
<ul>
<li>v.d as the shortest-path estimate</li>
<li>v.$\pi$ as the current predecessor</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">// Initialise-Single-Source</span><br><span class="line">for each v in V:</span><br><span class="line">	v.d = infinity</span><br><span class="line">	v.pi = NULL</span><br><span class="line">s.d = 0</span><br><span class="line"></span><br><span class="line">//Relax Action for (u,v,w)</span><br><span class="line">if v.d &gt; v.u + w(u,v)</span><br><span class="line">	v.d = v.u + w(u,v)</span><br><span class="line">	v.pi = u</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">//Bellman-ford (G,w,s)</span><br><span class="line">//relax for each point</span><br><span class="line">for i =1 to |v|-1:</span><br><span class="line">	for each edge (u,v) in G.E</span><br><span class="line">		Relax(u,v,w)</span><br><span class="line">//check whether the negative cycle exists</span><br><span class="line">for each edge (u,v) in G.E:</span><br><span class="line">	if v.d &gt; u.d + w(u,v)</span><br><span class="line">		return FALSE</span><br><span class="line">return TRUE</span><br></pre></td></tr></table></figure>
<p>Note: the relax procedure executes in the same order for each iteration.</p>
<p>The computing complexity:$O(VE)$</p>
<p>Problem: how to prove the convergency of the algorithm</p>
<p>Proof: <a href="https://web.stanford.edu/class/archive/cs/cs161/cs161.1168/lecture14.pdf" target="_blank" rel="noopener">CS 161 Lecture 14 – Amortized Analysis Jessica Su (some parts copied from CLRS)</a></p>
<h3 id="Properties-Lemma"><a href="#Properties-Lemma" class="headerlink" title="Properties(Lemma):"></a>Properties(Lemma):</h3><ul>
<li>Upper-bound property<ul>
<li>we always have $v.d \ge \delta(s,v) $ for all $v \in V$. Once v.d achieves $\delta(s,v)$ it never changes</li>
</ul>
</li>
<li>Convergence Property<ul>
<li>if $s \to u \to v$ is a shortest path in G for some $u,v \in V$, and if $u.d = \delta(s,u)$ at any time prior to relaxing edge(u,v) then $v.d = \delta(s,v) $ at all times afterwards</li>
</ul>
</li>
<li>no-path property<ul>
<li>if there is no path from s to v, then we always have $v.d = \delta(s,v) = \infty$</li>
</ul>
</li>
<li>triangle inequality<ul>
<li>For any edge (u,v) $\in$ E, we have $\delta(s,v) \le \delta(s,u) + w(u,v)$</li>
</ul>
</li>
</ul>
<p>Reference:</p>
<ol>
<li><a href="https://www.jianshu.com/p/c5b62a3a977b" target="_blank" rel="noopener">https://www.jianshu.com/p/c5b62a3a977b</a></li>
<li><a href="https://courses.csail.mit.edu/6.006/spring11/lectures/lec15.pdf" target="_blank" rel="noopener">https://courses.csail.mit.edu/6.006/spring11/lectures/lec15.pdf</a></li>
<li><a href="https://web.stanford.edu/class/archive/cs/cs161/cs161.1168/lecture14.pdf" target="_blank" rel="noopener">https://web.stanford.edu/class/archive/cs/cs161/cs161.1168/lecture14.pdf</a></li>
</ol>
<script type="math/tex; mode=display">
\ge</script>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/01/28/NOTE-Week-3-Distributed-System/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/28/NOTE-Week-3-Distributed-System/" itemprop="url">(DS) Clocks</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-28T10:40:10+00:00">
                2019-01-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview:"></a>Overview:</h2><ol>
<li>Logical clocks: ensure the total ordering</li>
<li>Vector clocks</li>
<li>stability of emssages</li>
</ol>
<p>Use clocks to ensure the total ordering</p>
<h2 id="Logical-Clocks"><a href="#Logical-Clocks" class="headerlink" title="Logical Clocks"></a>Logical Clocks</h2><p>Unlike a physical clock, it does not progress if no event occurs.</p>
<p>Mapping C between events and integers, if event e1 occurred before e2, then</p>
<p>C(e1) &lt; C(e2)</p>
<p>a higher value indicates a later point in time</p>
<p>Logical clocks in a distributed system can maintain <strong>causal</strong> or <strong>total</strong> orderings </p>
<h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p>Whenever a process broadcasts a message, it:</p>
<ol>
<li>Adds 1 to its clock as broadcast is an event </li>
<li>Sends the clock time along with message</li>
</ol>
<p>Whenever a process delivers a message:</p>
<ol>
<li>Adds 1 to its clock, as deliver is an event </li>
<li>If the message contains a higher or equal clock time than its own, it updates its clock to 1 more than this value, to ensure it is at least 1 tick on from sender</li>
</ol>
<p>Other events (internal events) in a process could also cause it to add 1 to its clock</p>
<h3 id="Properties"><a href="#Properties" class="headerlink" title="Properties:"></a>Properties:</h3><h2 id="Vector-Clock"><a href="#Vector-Clock" class="headerlink" title="Vector Clock"></a>Vector Clock</h2><p>Logical clock does not ensure total ordering because concurrent messages.</p>
<p>With vector clocks, each process Pi does not just keep a single logical clock value, but an array of them, one for each process in the system.</p>
<h3 id="Vector-Clock-Algorithm"><a href="#Vector-Clock-Algorithm" class="headerlink" title="Vector Clock Algorithm"></a>Vector Clock Algorithm</h3><p>Every process keeps an array of the clock value of all process, we denote the $P_i$ to be the vector Clock values stored in the process <strong>i.</strong> There are <strong>n</strong> processes in the whole system. </p>
<script type="math/tex; mode=display">
P_i=\begin{pmatrix}
p_{i,1}\\
p_{i,2}\\
\vdots \\
p_{i,i}\\
\vdots\\
p_{i,n}
\end{pmatrix}</script><ul>
<li>When Broadcasting a message, $p_{i,i}+1$, which is enough to ensure <strong>F</strong></li>
<li>when receiving a message from process, $p_{i,m} = max\{ p_{i,m}, p_{j,m}\}$</li>
</ul>
<p>When another process <strong>j</strong> sends a message M, it </p>
<ol>
<li>Change its own clock value $p_{j,j}+1$</li>
<li>Then send its whole vector $P_j$ to other processes:</li>
</ol>
<script type="math/tex; mode=display">
P_j=\begin{pmatrix}
p_{j,1}\\
p_{j,2}\\
\vdots \\
p_{j,j}\\
\vdots\\
p_{j,n}
\end{pmatrix}</script><p>After receiving the message M, the updating change in process i:</p>
<script type="math/tex; mode=display">
P_i=\begin{pmatrix}
max\{p_{i,1},p_{j,1}\}\\
max\{p_{i,2},p_{j,2}\}\\
\vdots \\
max\{(p_{i,i}+1),p_{j,i}\}\\
\vdots\\
max\{p_{i,j},p_{j,j}\}\\
\vdots\\
max\{p_{i,n},p_{j,n}\}
\end{pmatrix}</script><p>Because of the algorithm that the only two way of changing the clock value of process <strong>i</strong> is:</p>
<ol>
<li>Receiving a message (for process i)</li>
<li>Broadcasting a message (for process i)</li>
</ol>
<p>So the only after the operation of process <strong>i</strong>, the clock value of <strong>i</strong> can be changed in the whole system scope. So $max\{(p_{i,i}+1),p_{j,i}\} = p_{i,i}+1$ and $max\{p_{i,j},p_{j,j}\} = p_{j,j}$</p>
<p>Example:</p>
<p><img src="https://i.postimg.cc/qM6ps9r9/DS-3-3.png" zoom="70%"></p>
<p>In the stable situation, the message M is a stable message, then $P_i$ should update like:</p>
<script type="math/tex; mode=display">
P_i \to^{P_j} P_i'=
\begin{pmatrix}
p_{i,1}\\
p_{i,2}\\
\vdots \\
p_{i,i}\\
\vdots \\
p_{j,j}
\vdots\\
p_{i,n}
\end{pmatrix}
\to^{P_j}
\begin{pmatrix}
p_{i,1}\\
p_{i,2}\\
\vdots \\
p_{i,i}+1\\
\vdots \\
p_{j,j}\\
\vdots\\
p_{i,n}
\end{pmatrix}</script><p>The clock value of other processes should be the same, but not always. we will continue discuss in the following part.</p>
<h2 id="Stability-of-messages"><a href="#Stability-of-messages" class="headerlink" title="Stability of messages"></a>Stability of messages</h2><h4 id="Stable-Messages"><a href="#Stable-Messages" class="headerlink" title="Stable Messages:"></a>Stable Messages:</h4><p>A message M is stable at a process P if P knows that no other message that should be delivered before M is yet to be received by P.如果进程知道不会再收到该信息前的信息，那么这个信息就是稳定的。</p>
<h4 id="Knowing-stability-with-clocks"><a href="#Knowing-stability-with-clocks" class="headerlink" title="Knowing stability with clocks:"></a>Knowing stability with clocks:</h4><p>A process would know message M from process P is stable if it knew the clock of all processes was equal or greater than P’s clock in M.</p>
<h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h3><ul>
<li>when to deliver</li>
<li>whether a message with a lower clock value exists?</li>
<li>How long should the process wait before delivering the message?</li>
</ul>
<p>Example:</p>
<p><img src="https://i.postimg.cc/qqCWKHKw/DS-4-4.png" zoom="70%"></p>
<p>In this situation, we can regraded m2 and m1 as the causal ordering. </p>
<script type="math/tex; mode=display">
P_2=\begin{pmatrix}
0\\2\\ 1
\end{pmatrix}\\

P_1 \to^{P_2} P_1'= \begin{pmatrix}
1\\0\\ 0
\end{pmatrix}
\to^{P_2}
\begin{pmatrix}
2\\2\\ 1
\end{pmatrix}\\</script><p>In this transform example, <strong>i=1,j=2</strong>, But the value of process 3 changes in this process which should not happen. Thus Process 1 can determine that the message m2 should after one message from Process 3.</p>
<p>Exercise:</p>
<p><img src="https://i.postimg.cc/qRBw4KSG/ds-3-1.png" alt=""></p>
<p>Exercise answer:</p>
<ol>
<li>[m1,m2,m3],[m1,m3,m2]<ol>
<li>Reliable: [m1,m2,m3] [m1,m3,m2]</li>
<li>FIFO: [m1,m2,m3] [m3,m1,m2] [m1,m3,m2]</li>
<li>Causal: [m1,m3,m2] [m1,m2,m3]</li>
</ol>
</li>
<li>[m1,m3,m2] </li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/01/27/NOTE-Week-3-Pattern-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/27/NOTE-Week-3-Pattern-Recognition/" itemprop="url">(PR) Discriminant Function</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-27T22:10:35+00:00">
                2019-01-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol>
<li>Discriminant Functions</li>
<li>Equivalence to Bayesian Decision Theory </li>
<li>Decision Regions and Decision Boundaries </li>
<li>Dichotomizers </li>
<li>Linear Discriminant Functions </li>
<li>Generalised Linear Discriminant Functions </li>
<li>Learning Decision Boundaries<ul>
<li>perceptron learning </li>
<li>minimum squared error (MSE) procedures</li>
</ul>
</li>
</ol>
<h2 id="Discriminant-Function-判别式函数"><a href="#Discriminant-Function-判别式函数" class="headerlink" title="Discriminant Function(判别式函数)"></a>Discriminant Function(判别式函数)</h2><p>A discriminant function is a function, g, defined over the feature vector, x:$g(x)$. We define a separate functino for each class:</p>
<script type="math/tex; mode=display">
g_i(x) \text{for i =1,2,...c}</script><p>Assign feature vector $x$ to class j if:</p>
<script type="math/tex; mode=display">
j = arg \;max_{i \in c} g_i(x)</script><p>if the discriminant function:</p>
<script type="math/tex; mode=display">
g_i(x) = P(\omega_i|x)</script><p>Then we say it’s equal to the <a href="http://zhangzhejian.com/2019/01/21/NOTE-Week-2-Pattern-Recognition/">Bayseian Decision Theory</a>.</p>
<ul>
<li>Minimum Error Rate Classifier</li>
<li>Minimum Loss Classifier</li>
</ul>
<h3 id="Minimum-Error-rate"><a href="#Minimum-Error-rate" class="headerlink" title="Minimum Error rate"></a>Minimum Error rate</h3><script type="math/tex; mode=display">
g_i(x) = p(x|\omega_i)p(\omega_i)\\
g_i(x) = ln( p(x|\omega_i))+ln(p(\omega_i))</script><p>Assign feature vector x to class $\omega_j$ if:</p>
<script type="math/tex; mode=display">
\forall i \ne j, \; g_j(x) > g_i(x)</script><h3 id="Minimum-Loss-Classifier"><a href="#Minimum-Loss-Classifier" class="headerlink" title="Minimum Loss Classifier"></a>Minimum Loss Classifier</h3><script type="math/tex; mode=display">
g_i(x) = -R(\alpha_i|x)</script><p>Assign feature vector x to class $\omega_j$ if:</p>
<script type="math/tex; mode=display">
\forall i \ne j, \; g_j(x) < g_i(x)</script><h3 id="Regions-and-decision-Boundaries"><a href="#Regions-and-decision-Boundaries" class="headerlink" title="Regions and decision Boundaries"></a>Regions and decision Boundaries</h3><p>Region $R_i$ in which, $\forall j \ne i, g_i(x) &gt; g_j(x)$</p>
<h3 id="DIcchotomizers-二元-only-two-classes"><a href="#DIcchotomizers-二元-only-two-classes" class="headerlink" title="DIcchotomizers(二元) only two classes"></a>DIcchotomizers(二元) only two classes</h3><script type="math/tex; mode=display">
g(x) = g_1(x) - g_2(x)</script><p>if $g(x) &gt;0$, assign to class 1</p>
<h2 id="Linear-Discriminant-Function"><a href="#Linear-Discriminant-Function" class="headerlink" title="Linear Discriminant Function"></a>Linear Discriminant Function</h2><script type="math/tex; mode=display">
g(x) = w^Tx + w_0\\
g(x) = w_0+ \sum_{i} w_ix_i</script><p>Quadratic(平方)</p>
<script type="math/tex; mode=display">
g(x) =w_0+ \sum_{i} w_ix_i+ \sum_{i,j} w_{ij}x_ix_j</script><h3 id="Agumented-Vectors"><a href="#Agumented-Vectors" class="headerlink" title="Agumented Vectors"></a>Agumented Vectors</h3><script type="math/tex; mode=display">
g(x) = a^Ty\\
a = [w_0,w^T]\\
y = [1, x^T]</script><p>similar to the <a href="http://zhangzhejian.com/2018/09/13/Machine-Learning-Notes-StrandfordCourse/">Linear Regression part in ML</a></p>
<h2 id="Learning-Linear-Discriminant-Function"><a href="#Learning-Linear-Discriminant-Function" class="headerlink" title="Learning Linear Discriminant Function"></a>Learning Linear Discriminant Function</h2><p>Give a training dataset:</p>
<script type="math/tex; mode=display">
X = [(\vec{x_1},\omega_1);(\vec{x_2},\omega_2);....;(\vec{x_m},\omega_m)]</script><p>Determine weights:</p>
<script type="math/tex; mode=display">
\vec{\Theta_j} = [\theta_1,\theta_2,....\theta_n]\\
\Theta = [\vec{\Theta_1},....,\vec{\Theta_j}]</script><p>Where n is the dimension of the features, and m is the number of samples,and j is the number of classes.</p>
<p>Such that  $g_j(x_k) &gt; g_i(x_k) \forall i \ne j \; where\; j = \omege_k for all k $, if the solution exists, dataset is linearly separable.</p>
<h3 id="Two-category-Linear-Separable-case"><a href="#Two-category-Linear-Separable-case" class="headerlink" title="Two-category Linear Separable case"></a>Two-category Linear Separable case</h3><p>a sample $x_k$ is correctly classified if:<br>    $\theta x_k &gt;0 $ and $x_k$ is labelled $\omega_1$ or </p>
<p>​    $\theta x_k &lt;0 $ and $x_k$ is labelled $\omega_2$</p>
<script type="math/tex; mode=display">
x \to -x \;\;\forall x \in \omega_2\\
\theta x_k >0 \; \forall k</script><p>Gradient Descent Procedures to decrease the cost function </p>
<p>The Learning procedure is also similar to the <a href="http://zhangzhejian.com/2018/09/13/Machine-Learning-Notes-StrandfordCourse/">Linear Regression part</a>. Compared with the Linear Regression, the main difference between Classification and Regression can be obtained mainly from the Definition of cost Function.</p>
<p>As for Linear Regression:</p>
<p>The cost   function:</p>
<script type="math/tex; mode=display">
J(\theta) = (X \theta^T - Y)(X \theta^T - Y)^T</script><p>It calculates the <strong>Mean Square Error(MSE)</strong> of the model generated. However, in Linear Classification, the definition is a little bit different from the previous one.</p>
<h3 id="There-are-mainly-two-types"><a href="#There-are-mainly-two-types" class="headerlink" title="There are mainly two types:"></a>There are mainly two types:</h3><ul>
<li>Perceptron Algorithm(Sequential/Batch)<ul>
<li>Solves linear inequalities $\theta^T x_k&gt;0 \;\; forall k$</li>
<li>Learning driven by <strong>misclassified exemplars</strong></li>
<li>converges only if data is linearly separable</li>
</ul>
</li>
<li>Mean Squared Error Method(same as regression)<ul>
<li>solves linear equations $\theta^T x_k = b_k \;\; \forall k$</li>
<li>Learning depends on all exemplars</li>
<li>uses matrix inversion to calculate </li>
<li>Widrow-hoff(LMS, Least-Mean_Square) method</li>
</ul>
</li>
</ul>
<h3 id="Perceptron-Algorithm-Sequential-Batch-based-on-misclassified-exemplars"><a href="#Perceptron-Algorithm-Sequential-Batch-based-on-misclassified-exemplars" class="headerlink" title="Perceptron Algorithm(Sequential/Batch) (based on misclassified exemplars)"></a>Perceptron Algorithm(Sequential/Batch) (based on misclassified exemplars)</h3><p>the Cost function only depends on the <strong>misclassified exemplars</strong>.</p>
<h4 id="Batch"><a href="#Batch" class="headerlink" title="Batch"></a>Batch</h4><script type="math/tex; mode=display">
J(\theta) = \sum_{x\in\mathcal{X}} -\theta^T x\\
\text{where $\mathcal{X} $ is the set of sample misclassified by $\theta$}\\
\frac{d}{d\theta}J(\theta) = \sum_{x\in\mathcal{X}}-x\\
\theta = \theta -\eta \frac{d}{d\theta}J(\theta)</script><p><img src="https://i.postimg.cc/7ZW3Bd20/PR-3-1.png" alt=""></p>
<p>Converges when $\mathcal{X}$ is empty. which means the dataset is not linearly separable,if it is not convergency.</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">m=<span class="built_in">size</span>(x,<span class="number">1</span>)</span><br><span class="line">iterationTime = m;</span><br><span class="line">alpha = <span class="number">0.1</span>;</span><br><span class="line"><span class="keyword">while</span> true</span><br><span class="line">	misclassified = <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m</span><br><span class="line">		delta=<span class="number">0</span>;</span><br><span class="line">		J=<span class="number">0</span>;</span><br><span class="line">		<span class="keyword">if</span> x(<span class="built_in">i</span>,:)*theta &lt;<span class="number">0</span></span><br><span class="line">			J = J + (-x(<span class="built_in">i</span>,:)*theta)</span><br><span class="line">			delta = delta + (-x(<span class="built_in">i</span>,:))</span><br><span class="line">			misclassified = misclassified +<span class="number">1</span>;</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line"> 		theta = theta - eta*delta</span><br><span class="line">	<span class="keyword">end</span> </span><br><span class="line">	<span class="keyword">if</span> misclassified = <span class="number">0</span></span><br><span class="line">		<span class="keyword">break</span></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h4 id="Sequential"><a href="#Sequential" class="headerlink" title="Sequential"></a>Sequential</h4><p>Update based only on single sample errors.</p>
<script type="math/tex; mode=display">
\frac{d}{d\theta}J(\theta) = \sum_{x\in\mathcal{X}}-x_k</script><p><img src="https://i.postimg.cc/T3wjJfpT/pr-3-2.png" alt=""></p>
<p>​    </p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">While true:</span><br><span class="line">	misclasified = <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:m:</span><br><span class="line">		<span class="keyword">if</span> g(x_i)&lt;<span class="number">0</span>:</span><br><span class="line">			a = a - eta*y(<span class="built_in">i</span>,:)</span><br><span class="line">			misclassified  = misclassified+ <span class="number">1</span></span><br><span class="line">		<span class="keyword">end</span> </span><br><span class="line">	<span class="keyword">end</span> </span><br><span class="line">	<span class="keyword">if</span> misclassified ==<span class="number">0</span>:</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">	<span class="keyword">end</span> </span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h4 id="Multiclass-perceptron-Learning-Algorithm"><a href="#Multiclass-perceptron-Learning-Algorithm" class="headerlink" title="Multiclass perceptron Learning Algorithm"></a>Multiclass perceptron Learning Algorithm</h4><p><img src="https://i.postimg.cc/MZBzXQ5S/pr-3-3.png" alt=""></p>
<h2 id="MSE"><a href="#MSE" class="headerlink" title="MSE"></a>MSE</h2><p>the same as <a href="http://zhangzhejian.com/2018/09/13/Machine-Learning-Notes-StrandfordCourse/">Linear Regression part</a>.</p>
<h3 id="MSE-via-Pseudoinverse-伪逆矩阵"><a href="#MSE-via-Pseudoinverse-伪逆矩阵" class="headerlink" title="MSE via Pseudoinverse(伪逆矩阵)"></a>MSE via Pseudoinverse(伪逆矩阵)</h3><script type="math/tex; mode=display">
Ya = b\\
Y^TYa = Y^Tb\\
(Y^TY)^T Y^TYa = (Y^TY)^T Y^Tb\\
Ea = (Y^TY)^T Y^Tb\\
a =(Y^TY)^T Y^Tb\\
or \;\; a = Y^+ b</script><h3 id="Widrow-Hoff-or-LMS-algroithm"><a href="#Widrow-Hoff-or-LMS-algroithm" class="headerlink" title="Widrow-Hoff(or LMS) algroithm"></a>Widrow-Hoff(or LMS) algroithm</h3><ol>
<li>Initialise $\theta $ to arbitrary solution</li>
<li>for each sample $x_k$:<ul>
<li>Update solution: $\theta = \theta+\eta (b_k - \theta^T x_k)x_k$</li>
</ul>
</li>
<li>Iterate untill $\sum_k |(b_k - \theta^Tx_k)x_k|&lt;\Theta$</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">m=<span class="built_in">size</span>(x,<span class="number">1</span>);</span><br><span class="line">iterationTime = m;</span><br><span class="line">alpha = <span class="number">0.1</span>;</span><br><span class="line">y = X(:,<span class="number">4</span>);</span><br><span class="line">x = X(:,<span class="number">1</span>:<span class="number">3</span>)</span><br><span class="line">z = x .*y</span><br><span class="line"><span class="built_in">round</span> = <span class="built_in">fix</span>(iterationTime/m)</span><br><span class="line">r = <span class="built_in">mod</span>(iterationTime,m)</span><br><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="built_in">round</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:m</span><br><span class="line">    display(<span class="built_in">i</span>)</span><br><span class="line">    display(theta')</span><br><span class="line">    theta = theta - lamda* z(<span class="built_in">i</span>,:)' * (z(<span class="built_in">i</span>,:) * theta - b(<span class="built_in">i</span>,:));</span><br><span class="line">    J = (z*theta -b)'*(z*theta -b)</span><br><span class="line">    display(z(<span class="built_in">i</span>,:))</span><br><span class="line">    display(z(<span class="built_in">i</span>,:) * theta)</span><br><span class="line">    format short</span><br><span class="line">    display(theta')</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:r</span><br><span class="line">    display(<span class="built_in">i</span>)</span><br><span class="line">    display(theta')</span><br><span class="line">    theta = theta - lamda* z(<span class="built_in">i</span>,:)' * (z(<span class="built_in">i</span>,:) * theta - b(<span class="built_in">i</span>,:));</span><br><span class="line">    J = (z*theta -b)'*(z*theta -b)</span><br><span class="line">    </span><br><span class="line">    display(z(<span class="built_in">i</span>,:))</span><br><span class="line">    display(z(<span class="built_in">i</span>,:) * theta)</span><br><span class="line">    format short</span><br><span class="line">    display(theta')</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><a href="http://ecee.colorado.edu/~ecen4831/Demuth/Ch10_pres.pdf" target="_blank" rel="noopener">Convergence analysis</a></p>
<p>Reference:</p>
<ol>
<li><a href="https://blog.csdn.net/daunxx/article/details/51881956" target="_blank" rel="noopener">https://blog.csdn.net/daunxx/article/details/51881956</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/01/27/NOTE-Week-2-Cryptocurrencies/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/27/NOTE-Week-2-Cryptocurrencies/" itemprop="url">(Blockchain)Structure of the blockchain</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-27T09:34:32+00:00">
                2019-01-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Overview:</p>
<ul>
<li>Cryptographic Hash Functions</li>
<li>Digital Signatures</li>
<li>Blockchain structured in Bitcoin/Ethereum</li>
<li>UTXO in bitcoin</li>
<li>Account-based model in Ethereum</li>
</ul>
<h2 id="Cryptography"><a href="#Cryptography" class="headerlink" title="Cryptography"></a>Cryptography</h2><p>One-way Hash Function </p>
<p>Propety:</p>
<ol>
<li>Preimage Resistance(抗原像性)<ul>
<li>Given y, it is hard to find the x that h(x) = y</li>
<li>no clues or hints</li>
<li>给出密文，很难获得原文</li>
</ul>
</li>
<li>Second Preimage Resistance(弱抗碰撞性)<ul>
<li>given x and h(x) = y, it is computational hard to find a x’ such that h(x’) = y</li>
<li>很难找到两个不同的原文，使得两者拥有相同的hash密文</li>
</ul>
</li>
<li>Collision-Resistance(强抗碰撞性)<ul>
<li>it is hard to find two different messages, m1 and m2 such that h(m1)==h(m2)</li>
</ul>
</li>
</ol>
<h3 id="Bitcoin-Block-Header"><a href="#Bitcoin-Block-Header" class="headerlink" title="Bitcoin Block Header"></a>Bitcoin Block Header</h3><p><img src="https://i.postimg.cc/2jnQzKyT/BLC-2-1.png" alt=""></p>
<h3 id="How-to-verify-a-transaction-is-in-the-blockchain"><a href="#How-to-verify-a-transaction-is-in-the-blockchain" class="headerlink" title="How to verify a transaction is in the blockchain"></a>How to verify a transaction is in the blockchain</h3><p><img src="https://i.postimg.cc/BZhq1qjv/BLC-1-1.png" alt=""></p>
<p>Use the <strong>Merkle Root </strong> to verify</p>
<h2 id="Digital-Signature"><a href="#Digital-Signature" class="headerlink" title="Digital Signature"></a>Digital Signature</h2><p>We often call a cryptographic hash function a “commitment” and not an “encryption”. We open the preimage of a hash, there is no concept of decrypting or private keys. It is not about the data <strong>privacy</strong>, but the Integrity and authentication.</p>
<p>ECDSA Signature</p>
<p>an ECDSA signature is denoted: (r,s)</p>
<p>r is the randomness, s is the signature</p>
<h2 id="Bitcoin’s-UTXO-Model"><a href="#Bitcoin’s-UTXO-Model" class="headerlink" title="Bitcoin’s UTXO Model"></a>Bitcoin’s UTXO Model</h2><p>Reference:</p>
<ol>
<li><a href="http://8btc.com/article-4381-1.html" target="_blank" rel="noopener">http://8btc.com/article-4381-1.html</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/01/23/NOTE-Week-2-software-engineering/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/23/NOTE-Week-2-software-engineering/" itemprop="url">(Software Engineering) MDD</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-23T10:31:54+00:00">
                2019-01-23
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Key-points"><a href="#Key-points" class="headerlink" title="Key points:"></a>Key points:</h2><ol>
<li>Model-Driven development (MDD)</li>
<li>Model-Driven development (MDA)</li>
<li>Unified modelling language (UML)</li>
<li>Usecase diagrams (A type of UML diagram)</li>
</ol>
<h2 id="MDD"><a href="#MDD" class="headerlink" title="MDD"></a>MDD</h2><p>Model-Driven Development envisages(设想) development of software systems as a process consisting of:</p>
<ul>
<li>construction and transformation of <strong>models</strong></li>
<li>Semi-automated generation of executable code from models</li>
</ul>
<p>Can make production more efficient:</p>
<ul>
<li>Free developers from complexity of <strong>implementation details</strong>(开发者不用去关注实现的细节)</li>
<li><strong>Retaining core functionality</strong> of a system despite changes in its technology(技术的变化不会影响核心功能的模型变化)</li>
</ul>
<p>MDD is especially relevant for internet applications because of rapid changes in web technologies, and similar processes across many internet applications.互联网技术的变化非常快(架构，编程语言等)，并且应用之间有极大的相似之处(涉及到模型的相似)</p>
<h2 id="MDA-Model-Driven-Architecture"><a href="#MDA-Model-Driven-Architecture" class="headerlink" title="MDA(Model-Driven Architecture)"></a>MDA(Model-Driven Architecture)</h2><p>Constains:</p>
<ul>
<li><p>PIM (platform-independent models)</p>
</li>
<li><p>PSMs (platform-specific models)</p>
</li>
<li>Model transformations</li>
</ul>
<h3 id="PIM"><a href="#PIM" class="headerlink" title="PIM"></a>PIM</h3><ul>
<li>Implementation-indepndent constructs<ul>
<li>Express business rules that are core definition of functionalities of system(表述核心功能的业务逻辑)</li>
<li>Reusable across different paltforms</li>
<li>Flexible to accommodate enhancements and other backwards-compatible changes(对于之后的优化或者向后兼容的改变很灵活)</li>
</ul>
</li>
</ul>
<h3 id="PSM"><a href="#PSM" class="headerlink" title="PSM"></a>PSM</h3><p>Tailored to <strong>specific software platform and programming language</strong> and define functionalities of system in <strong>sufficient detail</strong> that they can be <strong>directly programmed</strong> from the model</p>
<h3 id="Model-Transformations"><a href="#Model-Transformations" class="headerlink" title="Model Transformations"></a>Model Transformations</h3><p>Produce a new model from an existing model</p>
<ul>
<li>improve the quality</li>
<li>Refine a PIM towards a PSM</li>
<li>refine a PSM to an implementation</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/01/21/NOTE-Week-2-Pattern-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/21/NOTE-Week-2-Pattern-Recognition/" itemprop="url">(PR) Bayesian Decision Theory and Density Estimation</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-21T12:10:40+00:00">
                2019-01-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>Bayesian Decision Theory</li>
<li>Bayesian Risk</li>
<li>Density Estiamtion<ul>
<li>Parametric<ul>
<li>Maximum-Likelihood Estimation</li>
</ul>
</li>
<li>Non-Parametric<ul>
<li>Parzen-Window Density Estimation</li>
<li>$k_n$ Nearest-Neighbour Density Estimation</li>
</ul>
</li>
</ul>
</li>
<li>K Nearest-Neighbor (KNN) Classification</li>
</ul>
<h2 id="Bayesian-Decision-Theory"><a href="#Bayesian-Decision-Theory" class="headerlink" title="Bayesian Decision Theory"></a>Bayesian Decision Theory</h2><p>Provide a method for making statistically optimal decisions</p>
<ul>
<li>Evidence vector x</li>
<li>Classes $\omega_j$</li>
</ul>
<script type="math/tex; mode=display">
P(\omega_j|x) = \frac{p(x|\omega_j)P(\omega_j)}{p(x)}\\
Posterior = \frac{Likelihood\times Prior}{Evidence}\\
后验概率 = \frac{可能性\times 先验概率}{观测证据}\\
p(x) = \sum_{j=1}^n p(x|\omega_j)p(\omega_j)\;\;(全概率公式)</script><h3 id="Bayes-Decision-Rule"><a href="#Bayes-Decision-Rule" class="headerlink" title="Bayes Decision Rule"></a>Bayes Decision Rule</h3><ul>
<li>If $P(\omega_1|x) &gt;P(\omega_2|x)  $, class as $\omega_1$</li>
<li>Otherwise class as $\omega_2$</li>
</ul>
<p><img src="https://i.postimg.cc/cCNfT2QH/pr-2-1.png" alt="Li"></p>
<h4 id="Likelihood-Ratio-Test-only-two-classes"><a href="#Likelihood-Ratio-Test-only-two-classes" class="headerlink" title="Likelihood Ratio Test(only two classes)"></a>Likelihood Ratio Test(only two classes)</h4><script type="math/tex; mode=display">
\begin{align}
& P(\omega_1|x) >P(\omega_2|x)\\
& \implies P(\omega_1|x)p(x) >P(\omega_2|x)p(x) \\
&\implies  P(x|\omega_1)p(\omega_1) >P(x|\omega_2)p(\omega_2) \\
& \implies \color{red}{\frac{P(x|\omega_1)}{P(x|\omega_2)}} > \frac{p(\omega_2)}{p(\omega_1)}
\end{align}</script><p>The left-hand is the likelihood Ratio</p>
<p>The right-hand is a constant</p>
<h4 id="General-use-in-classification"><a href="#General-use-in-classification" class="headerlink" title="General use in classification"></a>General use in classification</h4><ul>
<li>the data is multivariate<ul>
<li>x is a d-dimensional feature vector</li>
</ul>
</li>
<li>There are more than two states of nature(classes)<ul>
<li>$\omega$ is a finite set {$\omega_1,\omega_2…\omega_c$}</li>
<li>we choose the one with the max value of the posterior</li>
</ul>
</li>
</ul>
<p><img src="https://i.postimg.cc/VvBnhgRF/pr-2-2.png" alt=""></p>
<h3 id="Bayes-Risk"><a href="#Bayes-Risk" class="headerlink" title="Bayes Risk"></a>Bayes Risk</h3><p>To deal with the misclassifications.</p>
<h4 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h4><p>$\lambda(\alpha_i|\omega_j)$</p>
<ul>
<li>States how costly it is to take action $\alpha_i$ if the true state is $\omega_j$</li>
</ul>
<script type="math/tex; mode=display">
\mathcal{R}(\alpha_i|x) = \sum_{j=1}^c \lambda(\alpha_i|\omega_j)P(\omega_j|x)</script><p>For optimal performance, i.e. minimum loss</p>
<ul>
<li>Calculater $\mathcal{R}(\alpha_i|x)$ for all possible actions, then</li>
<li>Choose the action $\alpha_i$ for which $\mathcal{R}(\alpha_i|x)$ is minimum</li>
</ul>
<h2 id="Density-Estimation-估算的是概率密度"><a href="#Density-Estimation-估算的是概率密度" class="headerlink" title="Density Estimation(估算的是概率密度)"></a>Density Estimation(估算的是概率密度)</h2><p>To solve the problem in Bayesian Decision Theory that:</p>
<ul>
<li>$P(\omega_1)$</li>
<li>$p(x|\omega_1)$</li>
</ul>
<p>with the data we have.</p>
<p>Solution is to <u>estimate the probabilities from the data</u>, and this process is called <strong>Density Estimation</strong> </p>
<ul>
<li>for $p(\omega_j) = \frac{n_j}{n}$</li>
<li>for $p(x|\omega_1)$<ul>
<li>Parametric density Estimation</li>
<li>Non-Parametric Density Estimation</li>
</ul>
</li>
</ul>
<h2 id="Parametric-Density-Estimation"><a href="#Parametric-Density-Estimation" class="headerlink" title="Parametric Density Estimation"></a>Parametric Density Estimation</h2><p>Assumes the probability density can be described as a mathematical function, typically the Normal Distribution(假设概率密度分部遵从某种数学分布，比如正态分布，然后求分布的参数)</p>
<ul>
<li>for normal distribution<ul>
<li>Assume $p(x|\omega_i)\sim \mathcal{N}(\mu_i,\Sigma_i) $</li>
</ul>
</li>
<li>Need to estimate Parameters of this function<ul>
<li>use data to <strong>estimate $\mu_i$(the mean) and $\Sigma_i$ (the covariance协方差)</strong></li>
</ul>
</li>
</ul>
<p>Two estimation techniques:</p>
<ul>
<li><strong>Maximum-Likelihood(ML)</strong></li>
<li>Bayesian Parameter Estimation </li>
</ul>
<h3 id="Normal-Distribution-Example"><a href="#Normal-Distribution-Example" class="headerlink" title="Normal Distribution Example"></a>Normal Distribution Example</h3><ul>
<li><p>Univariate(1-D): $\mathcal{N}(\mu,\sigma)$</p>
<script type="math/tex; mode=display">
f(x) = \frac{1}{\sqrt{2\pi}\sigma}\exp(-0.5(\frac{x-\mu}{\sigma})^2)</script><ul>
<li>$\sigma$ is the standard deviation(标准差)</li>
</ul>
</li>
<li><p>Multivariate (d-D): $\mathcal{N}(\mu,\Sigma)$</p>
<script type="math/tex; mode=display">
f(x) = \frac{1}{\sqrt{(2\pi)^d}|\Sigma|}\exp(-0.5(x-\mu)^T\Sigma^{-1}(x-\mu))</script><ul>
<li>x is a column vector of length d</li>
<li>μ is a column vector of length d</li>
<li>$\Sigma$(协方差) is a d$\times$d matrix, with determinant $|\Sigma|$ and inverse $\Sigma^{-1}$</li>
</ul>
</li>
</ul>
<h3 id="Maximum-Likelihood-Estimation"><a href="#Maximum-Likelihood-Estimation" class="headerlink" title="Maximum-Likelihood Estimation"></a>Maximum-Likelihood Estimation</h3><p>Assume data contains n samples, and drawn <u>independently</u> from a multivariate normal distribution</p>
<ul>
<li><p>the mean $\mu$</p>
<script type="math/tex; mode=display">
\hat{\mu} = \frac{1}{n} \sum_{k=1}^nx_k</script></li>
<li><p>The covariance</p>
<script type="math/tex; mode=display">
\hat{\Sigma} = \frac{1}{n} \sum_{k=1}^n (x_k - \hat{\mu})(x_k - \hat{\mu})^T \; \; Biased</script><script type="math/tex; mode=display">
\hat{\Sigma} = \frac{1}{n-1} \sum_{k=1}^n (x_k - \hat{\mu})(x_k - \hat{\mu})^T \; \; unBiased</script></li>
</ul>
<h3 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h3><p>Parametric methods are limited:</p>
<ul>
<li>the distribution can be parameterised by a simple, unimodal, mathematical distribution</li>
<li>we know the mathematical function</li>
</ul>
<h2 id="Nonparametric-Density-Estimation"><a href="#Nonparametric-Density-Estimation" class="headerlink" title="Nonparametric Density Estimation"></a>Nonparametric Density Estimation</h2><h3 id="Parzen-window"><a href="#Parzen-window" class="headerlink" title="Parzen window"></a>Parzen window</h3><p>Reference: <a href="https://blog.csdn.net/shanglianlm/article/details/49839833" target="_blank" rel="noopener">https://blog.csdn.net/shanglianlm/article/details/49839833</a></p>
<p>Can be used for arbitrary and unknown distributions</p>
<ul>
<li>Window size: h</li>
<li>Volume of region: V</li>
<li>number of samples in region: k</li>
<li>Total number of samples: N</li>
</ul>
<p>To estimate the probability density in point x (x is a d-dimension vector):</p>
<script type="math/tex; mode=display">
\rho(x)= \frac{k(x)}{VN} \;\;     \text{（估算的是概率密度）}\\</script><p>$k(x)$ is the function $K: x \to number \; of \; samples \; in \; region$</p>
<script type="math/tex; mode=display">
Determine:\; \phi(\mu_1,\mu_2,...\mu_d) = 
\begin{cases} 
1 &\text{if $\mu_j \leq \frac{1}{2}$, j =1,2,3,...d}  &\text{(点在以x为中心的区域内，则为1)}\\
0 &\text{otherwise}
\end{cases}\\
k(x) = \sum_{i = 1}^N \phi(\frac{x_i-x}{h})\\
\rho(x) = \frac{1}{VN} \sum_{i = 1}^N \phi(\frac{x_i-x}{h})</script><p>From another way to see the function k, this one can be called window function:</p>
<script type="math/tex; mode=display">
K(x,x_i） = \frac{1}{V} \phi(\frac{x-x_i}{h})</script><p>The function $K(x,x_i)$ can be regarded as: the contribution of a single sample $x_i$ to the region (x,h). SO the density function can donate the average probability contribution to the region.</p>
<script type="math/tex; mode=display">
\rho(x) = \frac{1}{N} \sum_{i =1}^N K(x,x_i)</script><h4 id="Several-normal-window-functions"><a href="#Several-normal-window-functions" class="headerlink" title="Several normal window functions"></a>Several normal window functions</h4><ul>
<li>Square window<script type="math/tex; mode=display">
K(x,x_i) = 
\begin{cases} 
\frac{1}{h^d} &\text{if $|x^j - x_i^j| \leq \frac{h}{2}$, j =1,2,3,...d}  &\text{(点在以x为中心,距离为h/2的区域内，则为1)}\\
0 &\text{otherwise}
\end{cases}\\</script></li>
</ul>
<ul>
<li><p>Gaussian window</p>
<p>the Same as the normal distribution</p>
</li>
</ul>
<h4 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h4><p>Only works if we have lots of data available- an unquantifiable amount</p>
<h3 id="k-n-Nearest-Neighbour"><a href="#k-n-Nearest-Neighbour" class="headerlink" title="$k_n$ Nearest Neighbour"></a>$k_n$ Nearest Neighbour</h3><p>Can avoid problem of unknown best window size.</p>
<ul>
<li>let the volume be a function of the traning data</li>
<li>Centre a window about x and let it grow until it captures $k_n$ samples</li>
<li>These samples captured are the $k_n$ nearest-neighbours of x</li>
</ul>
<script type="math/tex; mode=display">
\rho(x) = \frac{k_n/N}{V}</script><p>Window size varies with density of data about x:</p>
<ul>
<li>High density<ul>
<li>Window be small which provide good resolution(分辨率)</li>
</ul>
</li>
<li>Low density<ul>
<li>Window wil be large, but estimated probability will be small</li>
<li>The continuity are ensured</li>
</ul>
</li>
</ul>
<p>Also requires lots of data</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/01/21/NOTE-Week-2-Distributed-System/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/21/NOTE-Week-2-Distributed-System/" itemprop="url">(DS) Reliable Broadcasts</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-21T12:10:15+00:00">
                2019-01-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ul>
<li>Reliable broadcasts</li>
<li>interaction models</li>
<li>Implementing reliable broadcasts</li>
</ul>
<h3 id="Key-points"><a href="#Key-points" class="headerlink" title="Key points:"></a>Key points:</h3><p>Broadcast properties</p>
<p>Order of message</p>
<ul>
<li>reliable</li>
<li>FIFO</li>
<li>Causal</li>
<li>Atomic</li>
</ul>
<p>Interaction models</p>
<p>implementation of reliable broadcast</p>
<p><strong>Broadcasting are used to ensure the consistency of the whole system during duplicatign.</strong></p>
<h2 id="Reliable-broadcasts"><a href="#Reliable-broadcasts" class="headerlink" title="Reliable broadcasts"></a>Reliable broadcasts</h2><p>Problems:</p>
<ul>
<li>processes receive messages in different order</li>
<li>even different messages</li>
<li>and sometimes process crashes</li>
</ul>
<p>Solution：</p>
<ul>
<li>Middleware</li>
</ul>
<p><img src="https://i.postimg.cc/BQrwYTx8/ds-2-3.png" alt=""></p>
<h3 id="Properties-of-Reliable-Broadcast"><a href="#Properties-of-Reliable-Broadcast" class="headerlink" title="Properties of Reliable Broadcast"></a>Properties of Reliable Broadcast</h3><ul>
<li>Agreement(一致性)<ul>
<li>if any <strong>correc</strong>t process delivers m, then all correct processes eventually deliver m</li>
<li>确保所有的进程都会收到同样的信息</li>
</ul>
</li>
<li>Validity(有效性)<ul>
<li>if a <strong>correct</strong> process executes broadcast(m) then all correct processes will eventually deliver m</li>
<li>一次广播，那么所有的都会收到信息，确保这次广播的是有效的</li>
</ul>
</li>
<li>Integrity(真实性)<ul>
<li>deliver(m) occurs at most once at each <strong>correct</strong> process, and only if broadcast(m) occurred in some process</li>
<li>只有当信息被广播之后，信息才会被送达且最多一次( 真实性，不存在欺骗，不会存在信息没有广播但是被送达的情况)</li>
</ul>
</li>
</ul>
<p>Note: a correct process is one that has not failed</p>
<h3 id="Uniform-Reliable-Broadcast"><a href="#Uniform-Reliable-Broadcast" class="headerlink" title="Uniform Reliable Broadcast"></a>Uniform Reliable Broadcast</h3><p>Uniform broadcasts ensure <strong>agreement and itegrity</strong> to allow failed processes to <strong>recover</strong></p>
<p>Properties of uniform reliable broadcast:</p>
<ul>
<li>Uniform agreement:<ul>
<li>if any process delivers m, then all correct processes eventually deliver m</li>
</ul>
</li>
<li>uniform integrity:<ul>
<li>deliver(m) occurs at most once at each process, and only if broadcast(m) occurred in some process.</li>
</ul>
</li>
</ul>
<p>注意和reliable broadcast的区别</p>
<h3 id="Order-of-messages"><a href="#Order-of-messages" class="headerlink" title="Order of messages"></a>Order of messages</h3><ul>
<li>FIFO<ul>
<li>Applies messages from a particular process</li>
<li>对于一个进程按一定顺序发出的信息，其他所有进程收到的顺序也得遵从</li>
</ul>
</li>
<li>Causal ordering<ul>
<li>If message B is <strong>broadcast</strong> from P1 <strong>after</strong> message A is <strong>delivered</strong> at P1, then at all other processes, B must be delivered after A is delivered</li>
</ul>
</li>
<li>Total ordering<ul>
<li>the order of message delivery is the same at all processes</li>
<li>The transmission of messages forms atomic broadcasts (AB)</li>
<li>Atomic broadcast guarantee that:<ul>
<li>A message is delivered to all processes or to none at all</li>
<li>All messages are delivered in the same order to all processes.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Interaction-Model"><a href="#Interaction-Model" class="headerlink" title="Interaction Model"></a>Interaction Model</h2><p>Interaction model show the broadcast and delivery of message over time.</p>
<p>Focus on several examples</p>
<h2 id="Implementing-Reliable-Broadcast"><a href="#Implementing-Reliable-Broadcast" class="headerlink" title="Implementing Reliable Broadcast"></a>Implementing Reliable Broadcast</h2><p>References: <a href="http://fileadmin.cs.lth.se/cs/Personal/Amr_Ergawy/dist-algos-slides/fourth-presentation.pdf" target="_blank" rel="noopener">http://fileadmin.cs.lth.se/cs/Personal/Amr_Ergawy/dist-algos-slides/fourth-presentation.pdf</a></p>
<p>A message sent or received is augmented to include:</p>
<ul>
<li>message text or body</li>
<li>sequence number </li>
<li>Identifier of the transmitter</li>
</ul>
<p>The sequence number and identifier of transmitter form a systemwide unique identifier for a message</p>
<h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><h3 id="Reliable-broadcast-Algorithm"><a href="#Reliable-broadcast-Algorithm" class="headerlink" title="Reliable broadcast Algorithm"></a>Reliable broadcast Algorithm</h3><ul>
<li>Broadcast</li>
</ul>
<p>Define send(m,s,i) to process p and receive(m,s,i)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">s = 0</span><br><span class="line">for each process p:</span><br><span class="line">	send (m,s,i) to p</span><br><span class="line"></span><br><span class="line">s:= s+1</span><br></pre></td></tr></table></figure>
<ul>
<li>Receive </li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if recorded does not contain (m,s,i):</span><br><span class="line">	deliver(m)</span><br><span class="line">	add(m,s,i) to recorded</span><br><span class="line">	for each process p:</span><br><span class="line">		send (m,s,i) //re-broadcast to other process again</span><br></pre></td></tr></table></figure>
<ul>
<li>Agreement</li>
<li><p>validity:</p>
<ul>
<li>one link fails, message will still reach via other intermediate processes</li>
</ul>
</li>
<li><p>integrity</p>
<ul>
<li>Messages only delivered if not already recorded</li>
</ul>
</li>
</ul>
<h3 id="Uniform-RB-algorithm"><a href="#Uniform-RB-algorithm" class="headerlink" title="Uniform RB algorithm"></a>Uniform RB algorithm</h3><p>Receive:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if recorded does not contain (m,s,i):</span><br><span class="line">	add(m,s,i) to recorded</span><br><span class="line">	for each process p:</span><br><span class="line">		send (m,s,i) //re-broadcast to other process again</span><br><span class="line">	if send to all correct process:</span><br><span class="line">		deliver(m) //deliver after sending to others</span><br></pre></td></tr></table></figure>
<h3 id="Uniform-FIFO-algorithm"><a href="#Uniform-FIFO-algorithm" class="headerlink" title="Uniform FIFO algorithm"></a>Uniform FIFO algorithm</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">add(m,s,i) to recorded</span><br><span class="line">if recorded does not contain (m,s,i):</span><br><span class="line">	for each process p:</span><br><span class="line">		send (m,next[i],i) //re-broadcast to other process again</span><br><span class="line">	deliver(m) </span><br><span class="line">	next[i] = next[i]+1</span><br></pre></td></tr></table></figure>
<h3 id="Uniform-Causal-Algorithm"><a href="#Uniform-Causal-Algorithm" class="headerlink" title="Uniform Causal Algorithm"></a>Uniform Causal Algorithm</h3><p>Broadcast:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mc := concatenation of causes &amp; m </span><br><span class="line">causes := []</span><br><span class="line">for each process p :</span><br><span class="line">	send (mc,s,i) to p</span><br><span class="line">s:= s+1</span><br></pre></td></tr></table></figure>
<p>Receive:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if m is concatenation of (mc,sc,ic) &amp; m2:</span><br><span class="line">	receive(mc,sc,ic)</span><br><span class="line">	receive (m2, s, i)</span><br><span class="line">else</span><br><span class="line">	Add (m, s, i) to causes</span><br><span class="line">	same receive algorithm as for FIFO</span><br></pre></td></tr></table></figure>
<h3 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h3><p><img src="https://i.postimg.cc/KYFpFmpx/ds-2-1.png" alt=""></p>
<p><img src="https://i.postimg.cc/XY91Tr8s/ds-2-2.png" alt=""></p>
<p>Exercise answer:</p>
<p>i) ABC</p>
<p>ii) A</p>
<p>iii) A</p>
<p>iv) A</p>
<p>i)DF</p>
<p>ii)DF</p>
<p>iii)F</p>
<p>iv)</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">zhejian</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">60</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">27</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zhejian</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
