<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="Recap">
<meta property="og:url" content="https://zhangzhejian.com/page/2/index.html">
<meta property="og:site_name" content="Recap">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Recap">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zhangzhejian.com/page/2/"/>





  <title>Recap</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Recap</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">zhejian</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/03/04/NOTE-Week-8-Pattern-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/04/NOTE-Week-8-Pattern-Recognition/" itemprop="url">(PR) Support Vector Machines</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-04T13:35:18+00:00">
                2019-03-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Overview:</p>
<ul>
<li>Introduction</li>
<li>Linear SVM: Linearly Separable case</li>
<li>Linear SVM: Linearly non-Separable case</li>
<li>Nonlinear SVMs</li>
<li>Multi-class SVMs</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h3><ul>
<li>similar concept of linear machines with margins</li>
<li><strong>Clasifies two classes</strong></li>
<li>Computes the optimal weights instead of through training</li>
<li>Relies on preprocessing the data in a high dimension using Kernel functions</li>
</ul>
<p>SVM iis based on Linear Discriminant Functions</p>
<h3 id="Two-Class-Classification-Probelm"><a href="#Two-Class-Classification-Probelm" class="headerlink" title="Two-Class Classification Probelm"></a>Two-Class Classification Probelm</h3><ul>
<li>Labelled training samples: $S = {(x_1,y_1),(x_2,y_2), \dots ,(x_N,y_N)}$<ul>
<li>$x_i = [x_{i1},\dots, x_(id)]$</li>
<li>$y_i \in {-1,1}$</li>
<li>N is the number of samples</li>
</ul>
</li>
<li>Goal is to design a hyperplane which can classify correctly the training samples</li>
<li>SVM is to optimal :<ul>
<li>No errors</li>
<li>Distance or margin between nearest support vectors is maximal</li>
</ul>
</li>
</ul>
<p><img src="https://i.postimg.cc/0yjvWkZq/pr-8-1.png"></p>
<h2 id="Linear-SVM"><a href="#Linear-SVM" class="headerlink" title="Linear SVM"></a>Linear SVM</h2><p>Deal with linearly separable 2-class classification problem</p>
<ul>
<li><p>Hyperplane:$f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + w_o$</p>
</li>
<li><p>Find $\mathbf{w}$ and $w_0$ such that</p>
<ul>
<li><p>the margin is optimal</p>
</li>
<li><script type="math/tex; mode=display">
\begin{cases}
\mathbf{w^Tx} + w_0 \geq 1, \text{ $\forall \mathbf{x} \in $ class 1 ('1')} \\
\mathbf{w^Tx} + w_0 \leq -1, \text{ $\forall \mathbf{x} \in $ class 2 ('-1')}
\end{cases}</script></li>
</ul>
</li>
</ul>
<h3 id="Optimal-margin"><a href="#Optimal-margin" class="headerlink" title="Optimal margin"></a>Optimal margin</h3><p>Distance of a point from a hyperplane:</p>
<script type="math/tex; mode=display">
distance(x) = \frac{|f(\mathbf{x})|}{||\mathbf{w}||}</script><p>So the margin is given by:</p>
<script type="math/tex; mode=display">
\begin{align}
& min_{\mathbf{x_i}:y_i =-1} \frac{|f(\mathbf{x_i})|}{||\mathbf{w}||} + min_{\mathbf{x_i}:y_i =+1} \frac{|f(\mathbf{x_i})|}{||\mathbf{w}||}\\
 &= \frac{1}{||\mathbf{w}||}(min_{\mathbf{x_i}:y_i =-1} |f(\mathbf{x_i})| + min_{\mathbf{x_i}:y_i =+1} |f(\mathbf{x_i})|)\\
 &=\frac{2}{||\mathbf{w}||}
 \end{align}</script><p>The problem is transformed into:</p>
<script type="math/tex; mode=display">
max_{\mathbf{w}} \frac{2}{||\mathbf{w}||} \iff min_{\mathbf{w}} J(\mathbf{w}) = \frac{1}{2} ||\mathbf{w}||^2</script><p>Meanwhile, the classification should be correct. So:</p>
<script type="math/tex; mode=display">
y_i(\mathbf{w^Tx_i}+w_0) \geq 1</script><p>The original problem can be transfered into a Quadratic Programing</p>
<h3 id="Lagrange-multipliers-引入拉格朗日乘子"><a href="#Lagrange-multipliers-引入拉格朗日乘子" class="headerlink" title="Lagrange multipliers(引入拉格朗日乘子)"></a>Lagrange multipliers(引入拉格朗日乘子)</h3><script type="math/tex; mode=display">
\mathcal{\scr{L}}(\mathbf{w},w_0,\mathbf{\lambda}) =
\frac{1}{2} ||\mathbf{w}||^2 - \sum_{i=1}^N \lambda_i(y_i(\mathbf{w^Tx_i}+w_0)-1)\\
\text{where $\lambda = [\lambda_1\; \lambda_2 \dots \lambda_N]$, $\lambda_i \geq 0 $ for all $i = 1,2,\dots,N$}\\
\text{And let } \theta(\mathbf{w}) = \max_{\lambda} \mathcal{\scr{L}} (\mathbf{w},w_0,\mathbf{\lambda})</script><p>It is easy to prove that, </p>
<script type="math/tex; mode=display">
\min_{\mathbf{w},w_0} \theta(\mathbf(w)) = \min_{\mathbf{w},w_0} \max_{\lambda \geq0} 
\mathcal{\scr{L}}(\mathbf{w},w_0,\mathbf{\lambda})</script><h3 id="Solve-the-Dual-problem"><a href="#Solve-the-Dual-problem" class="headerlink" title="Solve the Dual problem"></a>Solve the Dual problem</h3><p>Use KKT conditions</p>
<script type="math/tex; mode=display">
\frac{\part \mathcal{\scr{L}}(\mathbf{w},w_0,\mathbf{\lambda})}
{\part \mathbf{w}} = 0 \implies \;\; \mathbf{w} = \sum_{i=1} ^N \lambda_i y_i \mathbf{x}_i\\
\frac{\part \mathcal{\scr{L}}(\mathbf{w},w_0,\mathbf{\lambda})}
{\part w_0} = 0 \implies \sum_{i=1}^N \lambda_i y_i = 0\\
\lambda_i(y_i (\mathbf{w}^T \mathbf{x_i} - w_0)-1) = 0</script><p>Put them into $\mathcal{\scr{L}}(\mathbf{w},w_0,\mathbf{\lambda})$:</p>
<script type="math/tex; mode=display">
\mathcal{\scr{L}}(\mathbf{\lambda}) = \sum_{i=1}^N \lambda_i - \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \lambda_i \lambda_j y_i y_j x_i^Tx_j</script><p>The dual problem is reduced to:</p>
<script type="math/tex; mode=display">
\max_{\lambda \geq 0} \left( \sum_{i=1}^N \lambda_i - \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \lambda_i \lambda_j y_i y_j x_i^Tx_j \right)\\
\text{subject ot } \begin{align} &\sum_{i=1}^N \lambda_i y_i = 0, \\
& \lambda_i \geq 0
\end{align}</script><h3 id="Support-Vector"><a href="#Support-Vector" class="headerlink" title="Support Vector"></a>Support Vector</h3><p>For those $\mathbf{x_i}$ with $\lambda_i \ne 0$, they are known as <strong>support vectors</strong>. As a result,</p>
<script type="math/tex; mode=display">
\mathbf{w} = \sum_{i=1} ^N \lambda_i y_i \mathbf{x}_i = \sum_{i=1} ^{N_s} \lambda_i y_i \mathbf{x}_i</script><ul>
<li>Support vector $\mathbf{x_i}$: $y_i (\mathbf{w}^T \mathbf{x_i} - w_0)-1 =0$</li>
</ul>
<h2 id="Non-separable-Case"><a href="#Non-separable-Case" class="headerlink" title="Non-separable Case"></a>Non-separable Case</h2><p><img src="https://i.postimg.cc/VLD1WrqR/pr-8-2.png"></p>
<p>Input:</p>
<ul>
<li><p>fall outside the band and are correctly classiﬁed</p>
<ul>
<li><script type="math/tex; mode=display">
y_i(\mathbf{w^Tx_i}+w_0) \geq 1</script></li>
</ul>
</li>
</ul>
<ul>
<li><p>fall inside the band and are correctly classiﬁed</p>
<ul>
<li><script type="math/tex; mode=display">
0 \leq y_i(\mathbf{w^Tx_i}+w_0) < 1</script></li>
</ul>
</li>
</ul>
<ul>
<li><p>misclassiﬁed</p>
<ul>
<li><script type="math/tex; mode=display">
y_i(\mathbf{w^Tx_i}+w_0) \leq 0</script></li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">
y_i(\mathbf{w^Tx_i}+w_0) \geq 1 - \xi_i\\
\xi_i = 0; or \;\; 0<\xi \leq 1 ; \;\; or \; \xi_i >1</script><p>Max the margin and min the number of misclassified point.</p>
<script type="math/tex; mode=display">
\min_{\mathbf{w},w_0, \xi} J(\mathbf{w},\xi) = \frac{1}{2}||w||^2 + C \sum_{i=1}^N \xi_i\\
subject \;\;to:
\begin{align}
& y_i(\mathbf{w^Tx_i}+w_0) \geq 1 - \xi_i\\
& \xi_i \geq 0
\end{align}</script><h3 id="Lagrange-multipliers"><a href="#Lagrange-multipliers" class="headerlink" title="Lagrange multipliers"></a>Lagrange multipliers</h3><script type="math/tex; mode=display">
\mathcal{\scr{L}}(\mathbf{w},w_0,\mathbf{\lambda},\mu, \xi) =
\frac{1}{2} ||\mathbf{w}||^2 + C \sum_{i=1}^N \xi_i -\sum_{i=1}^N \mu_i \xi_i - \sum_{i=1}^N \lambda_i(y_i(\mathbf{w^Tx_i}+w_0)-1+\xi_i)\\

\text{where $\lambda = [\lambda_1\; \lambda_2 \dots \lambda_N]$, $\lambda_i \geq 0 $ $\mu_i \geq 0$ for all $i = 1,2,\dots,N$ , }</script><h3 id="Apply-KKT-condition"><a href="#Apply-KKT-condition" class="headerlink" title="Apply KKT condition"></a>Apply KKT condition</h3><script type="math/tex; mode=display">
\frac{\part \mathcal{\scr{L}}(\mathbf{w},w_0,\mathbf{\lambda},\mu, \xi)}{\part \mathbf{w}}= 0 \implies \;\; \mathbf{w} = \sum_{i=1} ^N \lambda_i y_i \mathbf{x}_i\\
\frac{\part \mathcal{\scr{L}}(\mathbf{w},w_0,\mathbf{\lambda} ,\mu, \xi)}
{\part w_0} = 0 \implies \sum_{i=1}^N \lambda_i y_i = 0\\

\frac{\part \mathcal{\scr{L}}(\mathbf{w},w_0,\mathbf{\lambda} ,\mu, \xi)}
{\part \xi_i} = 0 \implies C-\mu_i - \lambda_i = 0</script><p>We have:</p>
<script type="math/tex; mode=display">
\mathcal{\scr{L}}(\mathbf{\lambda},\xi) = \sum_{i=1}^N \lambda_i - \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \lambda_i \lambda_j y_i y_j x_i^Tx_j</script><p>The dual problem is reduced to:</p>
<script type="math/tex; mode=display">
\max_{\lambda \geq 0} \left( \sum_{i=1}^N \lambda_i - \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \lambda_i \lambda_j y_i y_j x_i^Tx_j \right)\\
\text{subject ot } \begin{align} &\sum_{i=1}^N \lambda_i y_i = 0, \\
& 0\leq \lambda_i \leq C
\end{align}</script><h2 id="Non-linear-SVM"><a href="#Non-linear-SVM" class="headerlink" title="Non-linear SVM"></a>Non-linear SVM</h2><h2 id="Kernel-functions"><a href="#Kernel-functions" class="headerlink" title="Kernel functions"></a>Kernel functions</h2><script type="math/tex; mode=display">
K(\mathbf{x_i},\mathbf{x}) = \Phi(\mathbf{x_i})^T\Phi(\mathbf{x})</script><h2 id="Multi-class-SVM"><a href="#Multi-class-SVM" class="headerlink" title="Multi-class SVM"></a>Multi-class SVM</h2><ul>
<li>One against one</li>
<li>One against all</li>
<li>Binary decision tree</li>
<li>Bianary Coded</li>
</ul>
<p>Ref:</p>
<ol>
<li><a href="https://blog.csdn.net/v_JULY_v/article/details/7624837" target="_blank" rel="noopener">https://blog.csdn.net/v_JULY_v/article/details/7624837</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/02/27/NOTE-Week-7-Software-engineering/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/27/NOTE-Week-7-Software-engineering/" itemprop="url">(SE)Web Application Architecture</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-27T10:24:28+00:00">
                2019-02-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Overview:</p>
<ul>
<li>The ﬁve-tier web application architecture</li>
<li>Functional core of web applications</li>
<li>Approaches to the presentation tier<ul>
<li>Pure servlet</li>
<li>Pure JSP</li>
<li>Model-view-controller (MVC)</li>
</ul>
</li>
</ul>
<h2 id="Five-tier-web-application-architecture"><a href="#Five-tier-web-application-architecture" class="headerlink" title="Five-tier web application architecture"></a>Five-tier web application architecture</h2><ul>
<li>Client tier</li>
<li>Presentation tier</li>
<li>Business tier</li>
<li>Integration tier</li>
<li>Resource tier</li>
</ul>
<h3 id="Client-tier"><a href="#Client-tier" class="headerlink" title="Client tier"></a>Client tier</h3><h3 id="Presentation-tier"><a href="#Presentation-tier" class="headerlink" title="Presentation tier"></a>Presentation tier</h3><p>Consists of <strong>controller</strong> and <strong>view components</strong>, such as servlets and JSP</p>
<h3 id="Business-tier"><a href="#Business-tier" class="headerlink" title="Business tier"></a>Business tier</h3><p>Consists of beans:</p>
<ul>
<li>Session Beans(<strong>temporary</strong>), represent groups of business functions</li>
<li>Entity Beans, represent business and conceptual entities and persistent data.</li>
</ul>
<h3 id="Integration-tier"><a href="#Integration-tier" class="headerlink" title="Integration tier"></a>Integration tier</h3><p>contains database interfaces, interfaces to external web services</p>
<h3 id="Resource-tier"><a href="#Resource-tier" class="headerlink" title="Resource tier"></a>Resource tier</h3><p>Actual database, web services and other resources used by the system such as static files.</p>
<h2 id="Functional-Core-of-Web-applications"><a href="#Functional-Core-of-Web-applications" class="headerlink" title="Functional Core of Web applications"></a>Functional Core of Web applications</h2><h3 id="Typical-Functinoal-components"><a href="#Typical-Functinoal-components" class="headerlink" title="Typical Functinoal components:"></a>Typical Functinoal components:</h3><ul>
<li>Web pages</li>
<li>Controller/coordinator components</li>
<li>View/presentation server-side elements</li>
<li>Resources</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/02/26/NOTE-Week-7-OME/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/26/NOTE-Week-7-OME/" itemprop="url">Linear Programming</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-26T16:09:01+00:00">
                2019-02-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Standard-definition-of-Linear-Programmes"><a href="#Standard-definition-of-Linear-Programmes" class="headerlink" title="Standard definition of Linear Programmes"></a>Standard definition of Linear Programmes</h3><p>Find values of variable $x_1,x_2, \dots ,x_n$, which</p>
<script type="math/tex; mode=display">
\text{maximise  }c_1x_1 + c_2x_2+ \dots + c_nx_n\\
\text{subject to  } \begin{align}
&a_{11}x_{11}+a_{12}x_{12}+ \dots+ a_{1n}x_{1n} \leq b_1\\
& a_{21}x_{21}+a_{22}x_{22}+ \dots+ a_{2n}x_{2n} \leq b_2\\
&\text{     } \;\;\;\;\;\;\;\;\;\;\;\;\;\;\vdots



\end{align}</script>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/02/25/NOTE-Week-7-Pattern-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/25/NOTE-Week-7-Pattern-Recognition/" itemprop="url">(PR) Fuzzy Inference System(模糊推理)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-25T13:00:46+00:00">
                2019-02-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Overview:</p>
<ul>
<li>Fuzzy Inference System <ul>
<li>Fuzziﬁers </li>
<li>Knowledge Base </li>
<li>Fuzzy Inference Engine </li>
<li>Defuzziﬁcation </li>
</ul>
</li>
<li>Three Fuzzy Inference Systems</li>
<li>Neural Fuzzy Network</li>
</ul>
<h2 id="Introduction—Fuzzy-Logic"><a href="#Introduction—Fuzzy-Logic" class="headerlink" title="Introduction—Fuzzy Logic"></a>Introduction—Fuzzy Logic</h2><ul>
<li>Human can solve a lot of complex problems using imprecision such as common sense and expert knowledge</li>
<li>Common sense and expert knowledge can be represented by linguistic rules, say, in <strong>If-Then</strong> format.</li>
<li>Fuzzy logic is the theory of fuzzy sets, which is used to handle fuzziness/imprecision/ambiguity/vagueness.</li>
<li>By using fuzzy logic, “human spirit” can be computed/represented mathematically.</li>
</ul>
<h3 id="Linguistic-Rules"><a href="#Linguistic-Rules" class="headerlink" title="Linguistic Rules"></a>Linguistic Rules</h3><ul>
<li><p>Rule 1: If distance is small Then speed is low</p>
</li>
<li><p>Rule 2: If distance is medium Then speed is steady</p>
</li>
<li><p>Rule 3: If distance is large Then speed is high</p>
</li>
</ul>
<h3 id="FIS"><a href="#FIS" class="headerlink" title="FIS"></a>FIS</h3><p><img src="https://i.postimg.cc/VvgsfpbJ/pr-7-1.png"></p>
<ul>
<li>Fuzzifiers:</li>
<li>Knowledge Base:<ul>
<li>A database consisting of linguistic rules in <strong>If-Then</strong> format</li>
</ul>
</li>
<li>Fuzzy inference Engine<ul>
<li>Using the rules in knowledge base, it performs reasoning by producing a fuzzy output according to the fuzzy input given by the fuzziﬁer</li>
</ul>
</li>
<li>Defuzziers<ul>
<li>It converts the fuzzy output given by the fuzzy inference engine to produce a crisp (real-valued) output. This process is called defuzziﬁaction.</li>
</ul>
</li>
</ul>
<h2 id="Fuzzifiers"><a href="#Fuzzifiers" class="headerlink" title="Fuzzifiers"></a>Fuzzifiers</h2><p>The input is turned to fuzzy sets thought membership functions.</p>
<p>A fuzzy set is represented by a membership functions (associated with a label called fuzzy term or linguistic term).</p>
<h3 id="Membership-functions"><a href="#Membership-functions" class="headerlink" title="Membership functions:"></a>Membership functions:</h3><p>A membership function denoted by $\mu_A(x)$ corresponding to fuzzy set A is characterised by a linear/nonlinear function of premise variable x.</p>
<p>$ 0 \leq \mu_A(x) \leq 1$</p>
<h3 id="Property-of-membership-functions"><a href="#Property-of-membership-functions" class="headerlink" title="Property of membership functions:"></a>Property of membership functions:</h3><ul>
<li>Core</li>
<li>Support</li>
<li>Boundaries</li>
</ul>
<p><img src="https://i.postimg.cc/G2nkTwjc/pr-7-2.png" zoom="70%"></p>
<ul>
<li>Normal/subnormal fuzzy set:<ul>
<li>if its membership function has atleaast one element of x  whose grade is 1</li>
</ul>
</li>
</ul>
<p><img src="https://i.postimg.cc/q73s7Myb/pr-7-3.png"></p>
<ul>
<li>height of a fuzzy set $hgt(A)$<ul>
<li>$hgt(A) = max{\mu_A}$</li>
</ul>
</li>
<li>Convex/non-convex fuzzy set:<ul>
<li>If membership function are strictly monotonically increasing/decreasing or  strictly monotonically increasing then decreasing.</li>
</ul>
</li>
</ul>
<p><img src="https://i.postimg.cc/C1CbjPvb/pr-7-4.png"></p>
<h3 id="Fuzzification"><a href="#Fuzzification" class="headerlink" title="Fuzzification"></a>Fuzzification</h3><p>The process turning the crisp input to a fuzzy value</p>
<h2 id="Knowledge-Base"><a href="#Knowledge-Base" class="headerlink" title="Knowledge Base"></a>Knowledge Base</h2><p>The knowledge base is the rule base representing the expertise knowledge dealing with a speciﬁc problem.</p>
<p>Linguistic rule: IF premise (antecedent) THEN conclusion (consequent)</p>
<p><img src="https://i.postimg.cc/907jykVj/pr-7-5.png"></p>
<h2 id="Fuzzy-Inference-Engine"><a href="#Fuzzy-Inference-Engine" class="headerlink" title="Fuzzy Inference Engine"></a>Fuzzy Inference Engine</h2><p>to produce the fuzzy output according to the crisp inputs based on the knowledge (knowledge base) represented by IF-THEN rule. This is the process of reasoning</p>
<ul>
<li>Rule evaluation<ul>
<li>to apply the fuzzy set operators (AND,OR,NOT) to the antecedents to determine the firing strength of each rule</li>
</ul>
</li>
<li>Rule aggregation<ul>
<li>combine the output (consequents) fuzzy sets using the ﬁring strengths obtained in the process of rule evaluation.</li>
</ul>
</li>
</ul>
<h3 id="Operators"><a href="#Operators" class="headerlink" title="Operators"></a>Operators</h3><ul>
<li><p>OR</p>
<ul>
<li><script type="math/tex; mode=display">
\mu_{A \bigcup B}(x) = \mu_A(x) \or \mu_B(x) = max(\mu_A(x) , \mu_B(x))</script></li>
</ul>
</li>
</ul>
<ul>
<li><p>AND</p>
<ul>
<li><script type="math/tex; mode=display">
\mu_{A \bigcap B}(x) = \mu_A(x) \and \mu_B(x) = min(\mu_A(x) , \mu_B(x))</script></li>
</ul>
</li>
</ul>
<ul>
<li><p>NOT</p>
<ul>
<li><script type="math/tex; mode=display">
\mu_{\bar{A}}(x) = 1-\mu_A(x)</script></li>
</ul>
</li>
</ul>
<h2 id="Defuzzification"><a href="#Defuzzification" class="headerlink" title="Defuzzification"></a>Defuzzification</h2><p>a process to convert the fuzzy output (an inferred membership function) to a crisp value.</p>
<h3 id="Methods-for-defuzzification"><a href="#Methods-for-defuzzification" class="headerlink" title="Methods for defuzzification"></a>Methods for defuzzification</h3><ul>
<li>max membership principle</li>
<li>centroid method</li>
<li>Weighted average method</li>
<li>mean max membership</li>
<li>center of sums</li>
<li>Center of largest area</li>
<li>First of maxima</li>
</ul>
<h4 id="Max-Membership-Principle"><a href="#Max-Membership-Principle" class="headerlink" title="Max Membership Principle"></a>Max Membership Principle</h4><p>choose the peaked value as the output</p>
<script type="math/tex; mode=display">
\mu_C(z^*) \geq \mu_C(z) \;\forall z \in Z \text{  where $z^*$ is the defuzzified value }</script><h4 id="Centroid-method-重心"><a href="#Centroid-method-重心" class="headerlink" title="Centroid method(重心)"></a>Centroid method(重心)</h4><p>COA or COG</p>
<ul>
<li><p>Continuous from:</p>
<ul>
<li><script type="math/tex; mode=display">
z^* = \frac{\int \mu_C(z)z \rm dz}{\int \mu_C(z) \rm dz}</script></li>
</ul>
</li>
</ul>
<ul>
<li><p>Discrete form</p>
<ul>
<li><script type="math/tex; mode=display">
z^* = \frac{\sum_{z_i \in Z}\mu_C(z_i)z_i}{\sum_{z_i \in Z}\mu_C(z_i)}</script></li>
</ul>
</li>
</ul>
<h4 id="Weighted-Average-Method"><a href="#Weighted-Average-Method" class="headerlink" title="Weighted Average Method"></a>Weighted Average Method</h4><p>Computational efficient but symmetrical output membership functions required</p>
<script type="math/tex; mode=display">
z^* = \frac{\sum \mu_C(\bar{z_i})\bar{z_i}}{\sum \mu_C(\bar{z_i})}</script><p>$\bar{z}$ is the centroid of each symmetric inferred membership function </p>
<h4 id="Mean-Max-Membership"><a href="#Mean-Max-Membership" class="headerlink" title="Mean Max Membership"></a>Mean Max Membership</h4><p>Computational efficient.</p>
<script type="math/tex; mode=display">
z^* = \frac{a+b}{2}</script><h4 id="Center-of-Sums"><a href="#Center-of-Sums" class="headerlink" title="Center of Sums"></a>Center of Sums</h4><ul>
<li><p>Continuous form</p>
<ul>
<li><script type="math/tex; mode=display">
z^* = \frac{\sum_{k=1}^n \bar{z}_k\int \mu_{C_k}(z) \rm dz }{\sum_{k=1}^n \int \mu_{C_k}(z) \rm dz}</script></li>
<li><p>$\bar{z}_k$ is the centroid of the $k^{th}$ output membership function</p>
</li>
<li><p>$\int \mu_{C_k}(z) \rm dz$ is the area of the member function</p>
</li>
</ul>
</li>
<li><p>Discrete form</p>
<ul>
<li><script type="math/tex; mode=display">
z^* =\frac{\sum_{k=1}^n \bar{z}_k \sum_{z_i\in Z} \mu_{C_k}(z)  }{\sum_{k=1}^n \sum_{z_i\in Z} \mu_{C_k}(z) }</script></li>
</ul>
</li>
</ul>
<h4 id="Center-of-Largest-Area"><a href="#Center-of-Largest-Area" class="headerlink" title="Center of Largest Area"></a>Center of Largest Area</h4><h4 id="First-or-last-of-Maxima"><a href="#First-or-last-of-Maxima" class="headerlink" title="First(or last) of Maxima"></a>First(or last) of Maxima</h4><h2 id="Three-FIS"><a href="#Three-FIS" class="headerlink" title="Three FIS"></a>Three FIS</h2><ul>
<li>Mamdani FIS</li>
<li>Sugeno FIS</li>
<li>Tsukamoto FIS</li>
</ul>
<p>The main difference is in the consequents of the IF-THEN rules:</p>
<ul>
<li>Mamdani: Consequent membership functino is general membership function</li>
<li>Sugeno: mathematical function</li>
<li>Tsukamoto: monotonic membership function (单调函数)</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/02/25/NOTE-Week-7-Distributed-System/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/25/NOTE-Week-7-Distributed-System/" itemprop="url">(DS) Distributed Transcations</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-25T12:09:01+00:00">
                2019-02-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Overview:</p>
<ul>
<li>Distributed Transcation</li>
<li>Concurrency control</li>
<li>locking basics</li>
</ul>
<h2 id="Distributed-Transcation"><a href="#Distributed-Transcation" class="headerlink" title="Distributed Transcation"></a>Distributed Transcation</h2><h3 id="Transactions"><a href="#Transactions" class="headerlink" title="Transactions"></a>Transactions</h3><p>Actions of other activities cannot alter the outcome of the task. Such indivisible tasks are called transactions</p>
<p>事务提供一种机制将一个活动涉及的所有操作纳入到一个不可分割的执行单元，组成事务的所有操作只有在所有操作均能正常执行的情况下方能提交，只要其中任一操作执行失败，都将导致整个事务的回滚。简单地说，事务提供一种“要么什么都不做，要么做全套（All or Nothing）”机制。<a href="https://juejin.im/post/5b5a0bf9f265da0f6523913b" target="_blank" rel="noopener">link</a></p>
<h3 id="Transcation-State"><a href="#Transcation-State" class="headerlink" title="Transcation State"></a>Transcation State</h3><ul>
<li>Active:<ul>
<li>the initial state</li>
<li>the transaction stays in this state while it is executing</li>
</ul>
</li>
<li>partially committed<ul>
<li>after the final statement has been executed.</li>
</ul>
</li>
<li>failed<ul>
<li>after the discovery that normal execution can no longer proceed</li>
</ul>
</li>
<li>aborted<ul>
<li>after the transaction has been rolled back and the database restored to its state prior to the start of the transaction</li>
</ul>
</li>
<li>Committed<ul>
<li>after successful completion</li>
</ul>
</li>
</ul>
<h3 id="ACID-Properties"><a href="#ACID-Properties" class="headerlink" title="ACID Properties"></a>ACID Properties</h3><ul>
<li>Atomicity<ul>
<li>All or Nothing</li>
</ul>
</li>
<li>Consistency</li>
<li>Isolatin<ul>
<li>Independent of other transactions</li>
</ul>
</li>
<li>Durability<ul>
<li>Once compelte, system failure will not lose results.</li>
</ul>
</li>
</ul>
<h4 id="Maintaining-Atomicity-and-Durability"><a href="#Maintaining-Atomicity-and-Durability" class="headerlink" title="Maintaining Atomicity and Durability"></a>Maintaining Atomicity and Durability</h4><p>By having copies of actions in a log file which allows:</p>
<ul>
<li>Partially complete transcations to be undone</li>
<li>completed transactions to be redone</li>
</ul>
<h4 id="Maintaining-Consistency"><a href="#Maintaining-Consistency" class="headerlink" title="Maintaining Consistency"></a>Maintaining Consistency</h4><h4 id="Maintainging-Isolation"><a href="#Maintainging-Isolation" class="headerlink" title="Maintainging Isolation"></a>Maintainging Isolation</h4><p>Isolation is trivially realised by executing transactions one after another <strong>(serially)</strong></p>
<p>Concurrency control must be performed to ensure transcations are <strong>serialisable</strong></p>
<h3 id="Nested-Transactions"><a href="#Nested-Transactions" class="headerlink" title="Nested Transactions"></a>Nested Transactions</h3><h2 id="Concurrency-Control"><a href="#Concurrency-Control" class="headerlink" title="Concurrency Control"></a>Concurrency Control</h2><h3 id="Transaction-Managers"><a href="#Transaction-Managers" class="headerlink" title="Transaction Managers"></a>Transaction Managers</h3><p>In a distributed environment:</p>
<ul>
<li>Local maintenance of ACID is performed by a local transactino manager(LTM)</li>
<li>A global transaction manager(GTM) distributes requests to and coordinates execution of LTMs<ul>
<li>To avoid single point failure, several GTMs will be used in the system</li>
</ul>
</li>
</ul>
<p>Concurrency control is the maintenance of the <strong>serialisability</strong> of transaction execution. The execution of a transaction can be viewed as a sequence of <strong>read</strong> and <strong>write</strong> operations</p>
<ul>
<li>rA(O) = a read of object O in transaction A</li>
<li>wA(O) = a write to object O in transaction A</li>
</ul>
<h3 id="Serially-Equivalent"><a href="#Serially-Equivalent" class="headerlink" title="Serially Equivalent"></a>Serially Equivalent</h3><p>For a combined sequence to meet the ACID properties, the result of execution must be the same as executing one transaction then the other</p>
<h3 id="View-Equivalence-Rules"><a href="#View-Equivalence-Rules" class="headerlink" title="View Equivalence Rules"></a>View Equivalence Rules</h3><ul>
<li><p>For each data item Q, if Transaction Ti reads the initial value of Q in S1, then Ti must, in S2, also read the initial value of Q.</p>
</li>
<li><p>For each data item Q, if Transaction Ti executes read(Q) in S1 and that value was produced by transaction Tj, then transaction Ti must in S2 also read the value of Q produced by transaction Tj.</p>
</li>
<li><p>For each data item Q, the transaction (if any) that performs the final write(Q) operation in S1 must perform the final write(Q) operation in S2.</p>
</li>
</ul>
<h3 id="Enforcing-Serialisability-Rules"><a href="#Enforcing-Serialisability-Rules" class="headerlink" title="Enforcing Serialisability Rules"></a>Enforcing Serialisability Rules</h3><ul>
<li>Timestamping</li>
<li>Optimistic Concurrency Control</li>
<li>Locking</li>
</ul>
<h2 id="Locking-Basics"><a href="#Locking-Basics" class="headerlink" title="Locking Basics"></a>Locking Basics</h2><h3 id="Two-phase-Locking-2PL"><a href="#Two-phase-Locking-2PL" class="headerlink" title="Two phase Locking(2PL)"></a>Two phase Locking(2PL)</h3><ul>
<li>Prevents a read or write command if it would cause rules to be violated</li>
<li>Works by placing locks on the objects, preventing operations that are not permitted</li>
<li>Locks can restrict reading and/or writing</li>
</ul>
<h3 id="Two-types-of-Lock"><a href="#Two-types-of-Lock" class="headerlink" title="Two types of Lock"></a>Two types of Lock</h3><ul>
<li><strong>Read locks</strong>: Placed on an object whenever a process wishes to read its contents<ul>
<li>May be obtained by any number of processes</li>
<li>Cannot be obtained if write lock exists on object</li>
</ul>
</li>
<li><strong>Write locks</strong>: placed on an object whenever a process wishes to change its contents<ul>
<li>A write lock on an object may be obtained by only one process at any particular time, only if either:<ul>
<li>there are no read locks present, or</li>
<li>the only read lock is held by the process itself</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Two-phases-of-locking"><a href="#Two-phases-of-locking" class="headerlink" title="Two phases of locking"></a>Two phases of locking</h3><p>Transaction execution involves two phases:</p>
<ul>
<li>Growing phase:<ul>
<li>Require additional locks to be obtained</li>
<li>Transactions may obtain locks, may not release locks</li>
</ul>
</li>
<li>Shrinking Phase<ul>
<li>Do not require additional locks to be obtained</li>
<li>Transaction may release locks, may not obtain locks</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/02/19/NOTE-Week-6-OME/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/19/NOTE-Week-6-OME/" itemprop="url">(OM)Minimum cost ﬂow problem Multicommodity ﬂow problems</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-19T16:08:20+00:00">
                2019-02-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Basic-definition"><a href="#Basic-definition" class="headerlink" title="Basic definition"></a>Basic definition</h2><p>A flow network:</p>
<script type="math/tex; mode=display">
G = (V, E,u,c,d)</script><ul>
<li>$u(v,w) \geq 0$ is the capacity of edge $(v,w)$ </li>
<li>$c(v,w) $ is the cost of one unit of flow on  edge $(v,w)$ </li>
<li>for each node $v \in V$, $|d(v)|$ is the initial supply or demand at $v$</li>
</ul>
<p><strong>Objective</strong>: Find a ﬂow which satisﬁes the speciﬁed supply/demand values (or, if not possible, ﬁnd a ﬂow which maximizes the value of ﬂow) and has the minimum possible cost.</p>
<p>the <strong>cost of a flow</strong> $f$ is:</p>
<script type="math/tex; mode=display">
\sum_{(v,w)\in E} c(v,w) f(v,w)</script><p>A technical assumption:</p>
<p>if $(v,w) \in E$, then also $(w,v) \in E$, but either $u(v,w) =0$ or $u(w,v) =0$.</p>
<h2 id="Residual-network"><a href="#Residual-network" class="headerlink" title="Residual network"></a>Residual network</h2><p>In this kind of problem, the construct of residual network is similar to the<a href="http://zhangzhejian.com/2019/02/12/NOTE-Week-5-OME/"> previous one</a> but with one difference.</p>
<script type="math/tex; mode=display">
u_f(v,w) = u(v,w) - f(v,w)\\
u_f(w,v) = f(v,w)\\
c_f(v,w) = c(v,w)\\
c_f(w,v) = -c(v,w)</script><p><img src="https://i.postimg.cc/dtwvJktq/om-6-1.png" zoom="50%"></p>
<p>for each node $v \in V$ the residual supply/demand at $v$ is :</p>
<script type="math/tex; mode=display">
d_f(v) = d(v) - \sum_{(v,x) \in E} f(v,x) + \sum_{(z,v) \in E} f(z,v)</script><h2 id="Successive-shortest-path-algorithm"><a href="#Successive-shortest-path-algorithm" class="headerlink" title="Successive shortest path algorithm"></a>Successive shortest path algorithm</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">f = 0</span><br><span class="line">S = &#123;v in V: d_f(v)&gt;0&#125;##the nodes with positive redsidual supply</span><br><span class="line">while S is not empty do</span><br><span class="line">	compute the residual network G_f</span><br><span class="line">	select a node v in S </span><br><span class="line">	Compute a shortest-path tree T in G_f from v to all nodes reachable from v</span><br><span class="line">	if there is a node w in T with residual demand (d_f(w) &lt;0) then</span><br><span class="line">		p = the path in T from v to w</span><br><span class="line">		q = min&#123;d_f(v),-d_f(w), min &#123;u_f(x,y):(x,y) in P&#125;&#125;</span><br><span class="line">		f_P = the flow along P of value q</span><br><span class="line">		f = f + f_P</span><br><span class="line">		if d_f(v) = 0 then </span><br><span class="line">			S = S -&#123;v&#125;</span><br><span class="line">	else S = S-&#123;v&#125;</span><br><span class="line">	</span><br><span class="line">end while</span><br></pre></td></tr></table></figure>
<h3 id="Correctness"><a href="#Correctness" class="headerlink" title="Correctness"></a>Correctness</h3><h3 id="Running-time"><a href="#Running-time" class="headerlink" title="Running time"></a>Running time</h3><p>The best known running time of a minimum cost flow algorithm is $O(m^2log^2n)$</p>
<h2 id="Multicommodity-flow-problems"><a href="#Multicommodity-flow-problems" class="headerlink" title="Multicommodity flow problems"></a>Multicommodity flow problems</h2><ul>
<li><p>A directed network $G = (V,E,u)$, where $u(x,y) is the capacity of an edge $(x,y) \in E$</p>
</li>
<li><p>K commodities specified as a sequence $C = &lt;(s_1,t_1,d_1),\dots,(s_k,t_k,d_k)&gt;$</p>
<ul>
<li><p>$s_q \in V$ and $t_q \in V$ are the source and destination of commodity $q$</p>
</li>
<li><p>$d_q(&gt;0)$ is the demand of this commodity</p>
</li>
<li><p>flow $f_q$ is the flow of commodity $q$</p>
</li>
<li><p>The congestion of flow on an edge (x,y) is defined as:</p>
<ul>
<li><script type="math/tex; mode=display">
\frac{f(x,y), \text{the total flow on edge (x,y)}}{u(x,y)}</script></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Minimum-cost"><a href="#Minimum-cost" class="headerlink" title="Minimum-cost"></a>Minimum-cost</h3><p>the cost of a simultaneous flow $<f_1,f_2, \dots,="" f_k="">$ is equal to:</f_1,f_2,></p>
<script type="math/tex; mode=display">
\sum_{(v,w) \in E} c(v,w)f(v,w) = \sum_{(v,w) \in E} c(v,w)[f_1(v,w)+f_2(v,w)+ \dots + f_k(v,w)]</script><h3 id="Minimum-congestion"><a href="#Minimum-congestion" class="headerlink" title="Minimum-congestion"></a>Minimum-congestion</h3><script type="math/tex; mode=display">
\text{Minimise:} \; max\{\frac{f(x,y)}{u(x,y)}: \;(x,y) \in E\}</script>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/02/18/NOTE-Week-6-Pattern-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/18/NOTE-Week-6-Pattern-Recognition/" itemprop="url">(PR) Multilayer NN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-18T12:31:14+00:00">
                2019-02-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Overview:</p>
<ul>
<li>Feedforward NN<ul>
<li>Neuron Model </li>
<li>Three-Layer Fully-Connected Feedforward Neural Networks </li>
<li>Activation/Transfer Functions </li>
<li>XOR Problem </li>
<li>General Feed-Forward Operation </li>
<li>Expressive Power of Multi-Layer Networks </li>
<li>Network Topology</li>
</ul>
</li>
<li>Backpropagation Algorithm<ul>
<li>Network Operation Modes </li>
<li>Network Learning </li>
<li>Hidden-to-Output Weights </li>
<li>Input-to-Hidden Weights </li>
<li>Pseudo-Code Algorithm </li>
<li>Learning Curves</li>
</ul>
</li>
<li>Radial Basis Function NN<ul>
<li>RBF Network Learning</li>
</ul>
</li>
<li>Comparison of RBF and MLP Networks</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Network-Architectures"><a href="#Network-Architectures" class="headerlink" title="Network Architectures"></a>Network Architectures</h3><ul>
<li>Feedforward networks: no loop exists(static)</li>
<li>Feedback/Recurrent networks: loop exists(dynamic system)</li>
</ul>
<p><img src="https://i.postimg.cc/Kv78XK0G/pr-6-1.png"></p>
<h2 id="Feedforward-NN"><a href="#Feedforward-NN" class="headerlink" title="Feedforward NN"></a>Feedforward NN</h2><ul>
<li>A feedforward neural network (multilayer perceptron (MLP)) consists of one input layer, some hidden layers and one output layer.</li>
<li>Each layer is an array of neurons.</li>
<li>Layers are interconnected by links.</li>
<li>Each link is associate with a connection weight.</li>
</ul>
<p><img src="https://i.postimg.cc/wTYjb5c4/pr-6-2.png"></p>
<h3 id="Neuron-model"><a href="#Neuron-model" class="headerlink" title="Neuron model"></a>Neuron model</h3><p>a single bias unit model:</p>
<p><img src="https://i.postimg.cc/sfh2cHSZ/pr-6-3.png"></p>
<script type="math/tex; mode=display">
net_j = \sum_{i=1}^d x_i w_{ji} + w_{j0} = \sum_{i=0}^d x_iw_{ji} = w_j^Tx\\
where \;\; w_j= \begin{bmatrix} 
w_{j1}\\
w_{j2}\\
\vdots\\
w_{jd}\\
w_{j0}
\end{bmatrix}  \;\; x=\begin{bmatrix} 
x_{j1}\\
x_{j2}\\
\vdots\\
x_{jd}\\
1
\end{bmatrix}\\</script><p>Each hidden unit emits an output that is a nonlinear function of its activation:</p>
<script type="math/tex; mode=display">
y_j = f(net_j)</script><p>The activation function can be many kind.such as:</p>
<ul>
<li>Heavside</li>
<li>Linear transfer function:$f(n) = n$</li>
<li>sigmoid transfer function:$f(n) = \frac{2}{1+e^{-2n}} -1$</li>
<li>Logarithmic sigmoid: $f(n) = \frac{1}{1+e^{-n}}$</li>
<li>Radial basis transfer function:$f(n) = e^{-n^2}$</li>
</ul>
<h3 id="Feed-forward-Operation"><a href="#Feed-forward-Operation" class="headerlink" title="Feed-forward Operation"></a>Feed-forward Operation</h3><script type="math/tex; mode=display">
y_j = f(net_j)=f(w_j^Tx)\\
z_k = f(net_k) = f(w_k^Ty)\\
Z=\begin{bmatrix} 
z_{1}\\
z_{2}\\
\vdots\\
z_{k}\\
\end{bmatrix} = f(W_{kj}Y+W_{k0}) = f(W_{kj}f(W_{ji}x+W_{j0})+W_{k0})</script><h2 id="Backpropagation-Algorithm"><a href="#Backpropagation-Algorithm" class="headerlink" title="Backpropagation Algorithm"></a>Backpropagation Algorithm</h2><h2 id="Network-Learning"><a href="#Network-Learning" class="headerlink" title="Network Learning"></a>Network Learning</h2><p><img src="https://i.postimg.cc/XJx8ChdH/pr-6-7.png"></p>
<p>Training error:</p>
<script type="math/tex; mode=display">
J(w) = \frac{1}{2}\sum_{k=1}^c (t_k-z_k)^2 = \frac{1}{2}||t-z||^2</script><h3 id="Error-on-the-hidden-to-output-weights"><a href="#Error-on-the-hidden-to-output-weights" class="headerlink" title="Error on the hidden-to-output weights:"></a>Error on the hidden-to-output weights:</h3><script type="math/tex; mode=display">
\frac{\partial J}{\partial w_{kj}} = \frac{\partial J}{\partial net_k}\frac{\partial net_k}{\partial w_{kj}} = -\delta_k \frac{\partial net_k}{\partial w_{kj}}</script><p>Where the sensitivity of unit k is defined as:</p>
<script type="math/tex; mode=display">
\delta_k = -\frac{\partial J}{\partial net_k}</script><script type="math/tex; mode=display">
\delta_k = -\frac{\partial J}{\partial net_k} = -\frac{\partial J}{\partial z_k}\frac{\partial z_k}{\partial net_k} = (t_k-z_k) \frac{\partial f(net_k)}{\partial net_k} = (t_k-z_k)  f'(net_k)\\
net_k = \sum_{j=1}^{n_H}y_jw_{kj}+w_{k0} = \mathbf{w}_k^T\mathbf{y}</script><p>Then:</p>
<script type="math/tex; mode=display">
\frac{\partial net_k}{\partial w_{kj}} = y_j\;\;y_0=1 \;\;bias</script><p>Conclusion:</p>
<script type="math/tex; mode=display">
\Delta w_{kj} = -\eta \frac{\partial J}{\partial w_{kj}} =\eta \delta_ky_j =(t_k-z_k)  f'(net_k) y_j</script><h3 id="Error-on-the-input-to-hidden-weights"><a href="#Error-on-the-input-to-hidden-weights" class="headerlink" title="Error on the input-to-hidden weights:"></a>Error on the input-to-hidden weights:</h3><script type="math/tex; mode=display">
\frac{\partial J}{\partial w_{ji}} = \frac{\partial J}{\partial y_j} \frac{\partial y_j}{\partial net_j}\frac{\partial net_j}{\partial w_{ji}}</script><p>Since $J =\frac{1}{2}\sum_{k=1}^c (t_k-z_k)^2 , y_j = f(net_j)$ and $net_j = \mathbf{w}_j^T\mathbf{x}$</p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial y_j} = \sum_{k=1}^c \frac{\partial J}{\partial z_k} \frac{\partial z_k}{\partial y_j} = - \sum_{k=1}^c (t_k-z_k)\frac{\partial z_k}{\partial y_j}\\


\frac{\partial z_k}{\partial y_j} = \frac{\partial z_k}{\partial net_k}\frac{\partial net_k}{\partial y_j} = f'(net_k) \sum_{k=1}^c w_{kj}\\

\frac{\partial J}{\partial y_j} =-\sum_{k=1}^c (t_k-z_k) f'(net_k) w_{kj} = -\sum_{k=1}^c \delta_k w_{kj}</script><p>Meanwhile:</p>
<script type="math/tex; mode=display">
\frac{\partial y_j}{\partial net_j}= f'(net_j) \\

\frac{\partial net_j}{\partial w_{ji}} = x_i</script><p>Conclusion:</p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial w_{ji}} =  -\sum_{k=1}^c \delta_k w_{kj}f'(net_j) x_i \\

 \delta_j = -\sum_{k=1}^c \delta_k w_{kj}f'(net_j)\\


\Delta w_{ji} = -\eta \frac{\partial J}{\partial w_{ji}} 
= \eta \sum_{k=1}^c \delta_k w_{kj} f'(net_j) x_i = \eta \delta_j x_i = \eta f'(net_j)[\sum_{k=1}^c w_{kj}\delta_k] x_i</script><ul>
<li>Stochastic Backpropagation Algorithm</li>
</ul>
<p><img src="https://i.postimg.cc/zfZ0ZTqj/pr-6-4.png"></p>
<ul>
<li>Batch Backpropagation Algoritnm</li>
</ul>
<p><img src="https://i.postimg.cc/0Q9nrxMK/pr-6-5.png"></p>
<h2 id="Radial-Basis-Function-NN"><a href="#Radial-Basis-Function-NN" class="headerlink" title="Radial Basis Function NN"></a>Radial Basis Function NN</h2><p><img src="https://i.postimg.cc/q7sQkgRd/pr-6-6.png"></p>
<p>Difference from Feed-forward:</p>
<p>There is no bias on the input layer.</p>
<h3 id="Hidden-units"><a href="#Hidden-units" class="headerlink" title="Hidden units:"></a>Hidden units:</h3><p><img src="https://i.postimg.cc/FsYZYTRp/pr-6-8.png"></p>
<script type="math/tex; mode=display">
d_j = ||\mathbf{x} - \mathbf{c}_j||, j=1,...,n_H\\
\mathbf{x}=[x_1,x_2 \dots x_d] \;\; and \;\; \mathbf{c}_j = [c_{j1}, c_{j2} \dots c_{jd}]\\
y_j(\mathbf{x}) = h(d_j) = h(||\mathbf{x} - \mathbf{c}_j||)</script><ul>
<li>$\mathbf{c}_j$ can be preset or determined by a traning algorithm</li>
<li>$h()$ is a radial basis function (function and parameters can be different for each hidden unit).</li>
</ul>
<p><img src="https://i.postimg.cc/Gt8ymSQs/pr-6-9.png"></p>
<h3 id="Output-units"><a href="#Output-units" class="headerlink" title="Output units"></a>Output units</h3><p><img src="https://i.postimg.cc/mrL1Hrj4/pr-6-10.png"></p>
<script type="math/tex; mode=display">
\begin{align}
z_k(\mathbf{x}) = f(net_k) &=f(\sum_{j=1}^{n_H}w_{kj} y_j(\mathbf{x})+w_{k0})\\
&=f(\sum_{j=1}^{n_H}w_{kj} h(||\mathbf{x} - \mathbf{c}_j||)+w_{k0})
\end{align}</script><p>Training error:</p>
<script type="math/tex; mode=display">
J = \sum_{p=1}^n J_p = \frac{1}{2}\sum_{p=1}^n (t_p-z_p)^2</script><p>Two pahses of training:</p>
<ul>
<li>(Unsupervised )<strong>Determine the centres $\mathbf{c}_j$</strong><ul>
<li>Fixed centres selected at random</li>
<li>Clustering based approaches</li>
</ul>
</li>
<li>(Supervised)<strong>Determine the output weights $w_{kj}$</strong><ul>
<li>Computing the output weights using least squares method</li>
<li>Gradient descent appraoches</li>
</ul>
</li>
</ul>
<h3 id="Fixed-centres-selected-at-random"><a href="#Fixed-centres-selected-at-random" class="headerlink" title="Fixed centres selected at random"></a>Fixed centres selected at random</h3><ul>
<li>Simple and quick</li>
<li>Number of hidden units $n_H$ is less than the number of input patterns n</li>
<li>Procedure:</li>
</ul>
<ol>
<li><p>Choose number of hidden units $n_H$</p>
</li>
<li><p>pick randomly $n_H$ input pattern from the data set(with n input patterns) as the centres $\mathbf{c}_j, \; j=1, \dots , n_H$</p>
</li>
<li><p>When Gaussian function is employed, deﬁne $\sigma_j = \frac{\rho_{max}}{\sqrt{2n_H}}$ or $\sigma_j = 2\rho_{avg}$ for all j where $\rho_{max}$ is the maximum distance between the chosen centres and $\rho_{avg}$ is the average distance between the chosen centres</p>
</li>
<li><p>Other parameters are chosen randomly.</p>
</li>
</ol>
<p><img src="https://i.postimg.cc/L6ZSRS3v/pr-6-11.png"></p>
<h3 id="Clustering-based-approaches"><a href="#Clustering-based-approaches" class="headerlink" title="Clustering based approaches."></a>Clustering based approaches.</h3><p><u>K-Means Clustering</u></p>
<h3 id="least-squares-method-linear-output-function"><a href="#least-squares-method-linear-output-function" class="headerlink" title="least squares method (linear output function)"></a>least squares method (linear output function)</h3><p>$f()$ is a linear function </p>
<script type="math/tex; mode=display">
Y \times W_k = t_k\\
\implies W_k = Y^T\times t_k</script><h3 id="Gradient-descent-approach-Backpropagation"><a href="#Gradient-descent-approach-Backpropagation" class="headerlink" title="Gradient descent approach (Backpropagation)"></a>Gradient descent approach (Backpropagation)</h3><script type="math/tex; mode=display">
\Delta w_{kj} = -\eta \frac{\partial J}{\partial w_{kj}}\\
\Delta \sigma_j = -\eta \frac{\partial J}{\partial \sigma_j}\\
\Delta c_{ji} = -\eta \frac{\partial J}{\partial c_{ji}}</script><h2 id="Comparison-of-RBF-and-MLP-networks"><a href="#Comparison-of-RBF-and-MLP-networks" class="headerlink" title="Comparison of RBF and MLP networks"></a>Comparison of RBF and MLP networks</h2><ul>
<li><p>Similarities</p>
<ul>
<li>universal approximators</li>
</ul>
</li>
<li><p>Differences</p>
<ul>
<li>RBF have only on hidden layer while MLP can have more</li>
<li>RBF use different basis function</li>
<li>RBF networks compute the distance between the input patterns and centres while MLP networks compute the inner product of the input pattern and weights.</li>
<li>RBF are trained with two-phase algorithm but MLP networks are trained with a single-phase algorithm.</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/02/13/NOTE-Week-5-SIA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/13/NOTE-Week-5-SIA/" itemprop="url">(SIA)State Machine Diagram</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-13T10:40:00+00:00">
                2019-02-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Overview:</p>
<ul>
<li>State machine diagrams</li>
<li>Harel diagram</li>
<li>State machine diagrams for web applications development</li>
</ul>
<h2 id="State-Machine-Diagrams"><a href="#State-Machine-Diagrams" class="headerlink" title="State Machine Diagrams"></a>State Machine Diagrams</h2><ul>
<li>State machine diagram:<ul>
<li>represent the dynamic behaviour of a system</li>
</ul>
</li>
<li>Class diagram<ul>
<li>represent static structure</li>
</ul>
</li>
</ul>
<p>State machine diagrams seek to represent:</p>
<ul>
<li>States<ul>
<li>an abstraction of the attribute values of an object.</li>
</ul>
</li>
<li>Events<ul>
<li>something that happens at a point in time.</li>
</ul>
</li>
<li>Actions<ul>
<li>operation in response to an event.</li>
</ul>
</li>
<li>Activity<ul>
<li>performed as long as an object is in some state.</li>
</ul>
</li>
</ul>
<h2 id="Harel-Diagrams"><a href="#Harel-Diagrams" class="headerlink" title="Harel Diagrams"></a>Harel Diagrams</h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/02/12/NOTE-Week-5-OME/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/12/NOTE-Week-5-OME/" itemprop="url">(OM)Network Flow Problems and Ford-Fulkerson method</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-12T16:08:31+00:00">
                2019-02-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Flow-network"><a href="#Flow-network" class="headerlink" title="Flow network"></a>Flow network</h2><script type="math/tex; mode=display">
G = (V,E,c,s,t)</script><ul>
<li>$V$ – set of n nodes,$ E $– set of m directed edges (links);</li>
<li>for each $(u, v) \in E, c(u, v) \geq 0$ is the capacity of edge $(u, v)$;</li>
<li><p>two distinguished nodes: <strong>source</strong> $s$ and <strong>sink</strong> $t$. $(s \ne  t)$</p>
</li>
<li><p>Aim:</p>
<ul>
<li>find a maximum flow from the source to the sink:</li>
<li>a ﬂow of the maximum total amount, while the ﬂow on each edge is not greater than the capacity of this edge;</li>
<li>a continuous ﬂow of the maximum total rate, while the rate of ﬂow on each edge is not greater than the capacity of this edge.</li>
</ul>
</li>
</ul>
<h3 id="Flows-Feasibility-Problem-Transshipment-problem"><a href="#Flows-Feasibility-Problem-Transshipment-problem" class="headerlink" title="Flows-Feasibility Problem(Transshipment problem)"></a>Flows-Feasibility Problem(Transshipment problem)</h3><h2 id="Definition-of-the-value-of-flow"><a href="#Definition-of-the-value-of-flow" class="headerlink" title="Definition of the value of flow"></a>Definition of the value of flow</h2><p>Assume:</p>
<ul>
<li><p>If $(u,v) \in E$ ,then $(v,u) \in E$</p>
</li>
<li><p>A flow is a function $f: E \to R$, where $f(u,v) \geq 0$ is the flow on edge that has the following properties:</p>
<ul>
<li><p>Capacity constrants:</p>
<ul>
<li>$0 \leq f(u,v) \leq c(u,v)$</li>
</ul>
</li>
<li><p>Flow conservation:(对于除了原点和终点之外的点)</p>
<ul>
<li><p>For each node $v \in V-{s,t}$, the total flow into $v$ is equal to the total flow out of $v$</p>
</li>
<li><script type="math/tex; mode=display">
\sum_{(x,v) \in E} f(x,v) = \sum_{(v,z)\in E} f(v,z)</script></li>
</ul>
</li>
<li><p>For each edge $(u,v) \in E$, if $f(u,v) &gt;0$, then $ f(v,u) =0$</p>
</li>
<li><p>If $f(v,u) = c(v,u)$, then we say that the flow saturates edge $(v,u)$, and edge $(v,u)$ is a saturated edge</p>
</li>
</ul>
</li>
</ul>
<p>The value of a ﬂow $f$ is the net ﬂow into the sink (which is equal to the net ﬂow from the source, due to the ﬂow conservation condition):</p>
<script type="math/tex; mode=display">
\begin{align}
|f|  &= \sum_{(x,t) \in E} f(x,t) - \sum_{(t,z)\in E} f(t,z)\\
&= \sum_{(s,v) \in E} f(s,v) - \sum_{(u,s)\in E} f(u,s)

\end{align}</script><h3 id="The-maximum-flow-problem"><a href="#The-maximum-flow-problem" class="headerlink" title="The maximum flow problem"></a>The maximum flow problem</h3><h2 id="Residual-Capacities-残余容量"><a href="#Residual-Capacities-残余容量" class="headerlink" title="Residual Capacities(残余容量)"></a>Residual Capacities(残余容量)</h2><p>The residual capacity of an edge $(u,v) \in E$ is defined as:</p>
<script type="math/tex; mode=display">
 c_f(u,v) = c(u,v) - f(u,v) \;\;\; \text{if $f(u,v) \geq 0 $ and $f(v,u) =0$;}\\
 c_f(u,v) = c(u,v) + f(u,v) \;\;\; \text{if $f(u,v) = 0$ and $f(v,u) \geq 0$;}\\</script><p>The residual network of $G$ included by flow f is the flow network $G_f = (V,E_f,c_f,s,t)$, where $c_f$ are the residual capacities and $E_f$ is the set of residual edges</p>
<h2 id="Max-flow-Min-cut-theorem最大流最小割定理"><a href="#Max-flow-Min-cut-theorem最大流最小割定理" class="headerlink" title="Max-flow Min-cut theorem最大流最小割定理"></a>Max-flow Min-cut theorem最大流最小割定理</h2><h2 id="Ford-Fulkerson-Method"><a href="#Ford-Fulkerson-Method" class="headerlink" title="Ford-Fulkerson Method"></a>Ford-Fulkerson Method</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">f = 0</span><br><span class="line">while true:</span><br><span class="line">	1. construct the residual network</span><br><span class="line">	2. find an augmenting path p, </span><br><span class="line">		if there is no agmenting path:</span><br><span class="line">			exit</span><br><span class="line">		end </span><br><span class="line">	3. f = f + f_p</span><br><span class="line"></span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<p>Running time:</p>
<script type="math/tex; mode=display">
O(E)+O(E)+O(E)</script><h2 id="Edmonds-Karp-algorithm"><a href="#Edmonds-Karp-algorithm" class="headerlink" title="Edmonds-Karp algorithm"></a>Edmonds-Karp algorithm</h2><p>when selecting the augmenting path, it uses BFS to find a shortest augmenting path.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">f = 0</span><br><span class="line">while true:</span><br><span class="line">	1. construct the residual network</span><br><span class="line">	2. BFS to find a shortest augmenting path p </span><br><span class="line">	3. if there is no agmenting path:</span><br><span class="line">			exit</span><br><span class="line">		end </span><br><span class="line">	3. f = f + f_p3</span><br><span class="line"></span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<p>Running time:</p>
<script type="math/tex; mode=display">
O(VE^2)</script>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhangzhejian.com/2019/02/11/NOTE-Week-5-Pattern-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Recap">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/11/NOTE-Week-5-Pattern-Recognition/" itemprop="url">(PR) Feature Extraction</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-11T12:02:17+00:00">
                2019-02-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Overview:</p>
<ul>
<li>Feature Selection </li>
<li>Feature Extraction:<ul>
<li>Principal Component Analysis (PCA) </li>
<li>Whitening </li>
<li>Linear Discriminant Analysis (LDA) </li>
<li>Independent Component Analysis (ICA) </li>
<li>Random Projections </li>
<li>Sparse Coding </li>
<li>Deep Learning</li>
</ul>
</li>
</ul>
<h2 id="Feature-Selection"><a href="#Feature-Selection" class="headerlink" title="Feature Selection"></a>Feature Selection</h2><p>Feature selection is the process of choosing the most discriminative subset of data on which to perform the classification process.</p>
<h2 id="Feature-Extraction"><a href="#Feature-Extraction" class="headerlink" title="Feature Extraction"></a>Feature Extraction</h2><p>Find features that are functions of the raw data.</p>
<p>Projects(投影) original data points into new feature space. Ideally, new feature space is one in which it is easier to classify data.</p>
<h3 id="Principal-Component-Analysis-PCA"><a href="#Principal-Component-Analysis-PCA" class="headerlink" title="Principal Component Analysis(PCA)"></a>Principal Component Analysis(PCA)</h3><p>Takes N-dimensional data and finds the M (M≤N) orthogonal<a href="https://zh.wikipedia.org/wiki/%E6%AD%A3%E4%BA%A4" target="_blank" rel="noopener">(正交的)</a> directions in which the data has the most variance</p>
<h3 id="Karhunen-Loeve-Transform-KLT"><a href="#Karhunen-Loeve-Transform-KLT" class="headerlink" title="Karhunen-Loève Transform (KLT)"></a>Karhunen-Loève Transform (KLT)</h3><ul>
<li><p>Calculate mean of all data vectors,$\mu = \frac{1}{N}\sum_{i=1}^N x_i$ </p>
</li>
<li><p>Calculate convariance matrix of <strong>zero-mean data</strong> 移动到原点</p>
<ul>
<li><script type="math/tex; mode=display">
C = \frac{1}{N} \sum_{i=1}^N(x_i-\mu)(x_i - \mu)^T</script></li>
</ul>
</li>
<li><p>Find eigenvalues (E) &amp; eigenvectors (V) of C by <strong>SVD</strong></p>
<ul>
<li><script type="math/tex; mode=display">
C = VEV^T</script></li>
</ul>
</li>
<li><p>Order eigenvalues from large to small, and discard small eigenvalues and their respective vectors</p>
</li>
<li><p>Form matrix $U$</p>
<script type="math/tex; mode=display">
y_i = U^T(x_i-\mu)</script></li>
</ul>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">X = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>;<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">2</span>;<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>];</span><br><span class="line"><span class="comment">%% m is the dimension and n is the number of samples</span></span><br><span class="line">[m,n] = <span class="built_in">size</span>(X);</span><br><span class="line">mu = <span class="built_in">zeros</span>(m,<span class="number">1</span>);</span><br><span class="line">k = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:m</span><br><span class="line">    mu(<span class="built_in">i</span>,:) = mean(X(<span class="built_in">i</span>,:));</span><br><span class="line"><span class="keyword">end</span> </span><br><span class="line">C = <span class="built_in">zeros</span>(m)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> =<span class="number">1</span>:n</span><br><span class="line">    C = C +(X(:,<span class="built_in">i</span>) - mu)*(X(:,<span class="built_in">i</span>) - mu)';</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">C = C ./n;</span><br><span class="line">[U,S,V] = svd(C)</span><br><span class="line">Ure = U(:,<span class="number">1</span>:k)</span><br><span class="line">y = <span class="built_in">zeros</span>(k,n);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n</span><br><span class="line">    </span><br><span class="line">   y(:,<span class="built_in">i</span>) = Ure' * (X(:,<span class="built_in">i</span>)-mu);</span><br><span class="line">    </span><br><span class="line"><span class="keyword">end</span> </span><br><span class="line">display(y)</span><br></pre></td></tr></table></figure>
<h3 id="Neural-Networks-for-PCA"><a href="#Neural-Networks-for-PCA" class="headerlink" title="Neural Networks for PCA"></a>Neural Networks for PCA</h3><p>Using zero-mean data as inpuit $x$</p>
<ul>
<li><p>Hebbian Learning</p>
<ul>
<li>$\Delta w = \eta y x^t$</li>
</ul>
</li>
<li><p>Oja’s rule</p>
<ul>
<li>$\Delta w = \eta y(x_i^t-yw)$</li>
</ul>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">X = [<span class="number">0</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">8</span>,<span class="number">9</span>;<span class="number">1</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">7</span>]</span><br><span class="line">[dimension,m] = <span class="built_in">size</span>(X);</span><br><span class="line">mu = <span class="built_in">zeros</span>(dimension,<span class="number">1</span>);</span><br><span class="line">eta = <span class="number">0.01</span>;</span><br><span class="line">w = [<span class="number">-1</span>,<span class="number">0</span>]</span><br><span class="line">iteration = <span class="number">100</span>;</span><br><span class="line">mu = <span class="built_in">zeros</span>(dimension,<span class="number">1</span>);</span><br><span class="line">k = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:dimension</span><br><span class="line">    mu(<span class="built_in">i</span>,:) = mean(X(<span class="built_in">i</span>,:));</span><br><span class="line">    X(<span class="built_in">i</span>,:) = X(<span class="built_in">i</span>,:) - mu(<span class="built_in">i</span>,:);</span><br><span class="line"><span class="keyword">end</span> </span><br><span class="line">display(mu);</span><br><span class="line">display(X);</span><br><span class="line"><span class="keyword">for</span> z = <span class="number">1</span>:iteration</span><br><span class="line">    dw =<span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m</span><br><span class="line">    	y = w*X(:,<span class="built_in">i</span>);</span><br><span class="line">    	dw = dw + eta*y*(X(:,<span class="built_in">i</span>)'-y*w)</span><br><span class="line">	<span class="keyword">end</span> </span><br><span class="line">    w = w + dw</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Linear-Discriminant-Analysis-LDA"><a href="#Linear-Discriminant-Analysis-LDA" class="headerlink" title="Linear Discriminant Analysis (LDA)"></a>Linear Discriminant Analysis (LDA)</h3><p>supervised</p>
<p><strong>Fisher’s method</strong> to find $w$ that <strong>maximises</strong>:</p>
<script type="math/tex; mode=display">
J(w) = \frac{sb}{sw}\\
sb = |w(m1-m2)|^2, m_i = \frac{1}{n_i}\sum_{\mathcal{X}\in \omega_i} \mathcal{x}\\
sw = \sum s_i^2\\
s_i^2 = \sum_{\mathcal{X}\in \omega_i} (w(x-m_1))^2</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">X = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>;<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>;<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>;<span class="number">2</span>,<span class="number">6</span>,<span class="number">5</span>;<span class="number">2</span>,<span class="number">7</span>,<span class="number">8</span>]</span><br><span class="line">T = X(:,<span class="number">1</span>)</span><br><span class="line">w_1 = [<span class="number">-1</span>,<span class="number">5</span>]';</span><br><span class="line">w_1 = [<span class="number">2</span>,<span class="number">-3</span>]';</span><br><span class="line">X_1 = X(X(:,<span class="number">1</span>)==<span class="number">1</span>,<span class="number">2</span>:<span class="number">3</span>)</span><br><span class="line">X_2 = X(X(:,<span class="number">1</span>)==<span class="number">2</span>,<span class="number">2</span>:<span class="number">3</span>)</span><br><span class="line">[dimension,m] = <span class="built_in">size</span>(X');</span><br><span class="line">meanMatrix = <span class="built_in">zeros</span>(dimension<span class="number">-1</span>,<span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> =<span class="number">1</span>:dimension<span class="number">-1</span></span><br><span class="line">    meanMatrix(<span class="number">1</span>,<span class="built_in">i</span>) = mean(X_1(:,<span class="built_in">i</span>));</span><br><span class="line">    meanMatrix(<span class="number">2</span>,<span class="built_in">i</span>) = mean(X_2(:,<span class="built_in">i</span>));</span><br><span class="line"><span class="keyword">end</span> </span><br><span class="line"></span><br><span class="line">sb =(w_1'*(meanMatrix(<span class="number">1</span>,:)-meanMatrix(<span class="number">2</span>,:))')^<span class="number">2</span></span><br><span class="line">n_1 = <span class="built_in">size</span>(X_1,<span class="number">1</span>);</span><br><span class="line">n_2 = <span class="built_in">size</span>(X_2,<span class="number">1</span>);</span><br><span class="line">s_1 = <span class="number">0</span>;</span><br><span class="line">s_2 = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n_1</span><br><span class="line">   s_1 = s_1 + (w_1'*(X_1(<span class="built_in">i</span>,:) - meanMatrix(<span class="number">1</span>,:))')^<span class="number">2</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">end</span> </span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n_2</span><br><span class="line">   s_2 = s_2 + (w_1'*(X_2(<span class="built_in">i</span>,:) - meanMatrix(<span class="number">2</span>,:))')^<span class="number">2</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">end</span> </span><br><span class="line">sw = s_1 + s_2</span><br><span class="line">J = sb/sw</span><br></pre></td></tr></table></figure>
<h2 id="Random-Projections"><a href="#Random-Projections" class="headerlink" title="Random Projections"></a>Random Projections</h2><p>Project the data into a spcae with higher dimensionality, in the new space feature vectors that were non separable may become separable.</p>
<h3 id="Extreme-Learning-Machines"><a href="#Extreme-Learning-Machines" class="headerlink" title="Extreme Learning Machines"></a>Extreme Learning Machines</h3><h3 id="Sparse-Coding"><a href="#Sparse-Coding" class="headerlink" title="Sparse Coding"></a>Sparse Coding</h3><p>Reference:</p>
<ol>
<li><a href="https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/articles/PCA.html" target="_blank" rel="noopener">https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/articles/PCA.html</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


      
    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">zhejian</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">75</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">27</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zhejian</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
